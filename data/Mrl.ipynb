{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef8aa328-46c8-4656-8b18-588a71631ab6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'toolz'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m sys.path.append(\u001b[33m'\u001b[39m\u001b[33mshared/team2/data/\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Import and run the loader\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mloader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MimicDataset\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Create dataset with all 4 models fused (\"All\" option)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading fused embeddings from all 4 models...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/shared/team2/data/loader.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtoolz\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtoolz\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcurried\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtoolz\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcurried\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moperator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'toolz'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('shared/team2/data/')\n",
    "\n",
    "# Import and run the loader\n",
    "from loader import MimicDataset\n",
    "\n",
    "# Create dataset with all 4 models fused (\"All\" option)\n",
    "print(\"Loading fused embeddings from all 4 models...\")\n",
    "dataset = MimicDataset(\n",
    "    mode=\"train\",\n",
    "    embedding_type=\"All\",  # This concatenates all 4 models\n",
    "    unique_patients=True\n",
    ")\n",
    "\n",
    "print(f\"Dataset created with {len(dataset)} samples\")\n",
    "\n",
    "# Get one sample to see the fused embedding shape\n",
    "sample = dataset[0]\n",
    "fused_embedding = sample[\"emb\"]\n",
    "labels = sample[\"lab\"]\n",
    "\n",
    "print(f\"Fused embedding shape: {fused_embedding.shape}\")\n",
    "print(f\"Labels shape: {labels.shape}\")\n",
    "\n",
    "# Load all samples\n",
    "print(\"Loading all fused embeddings...\")\n",
    "all_samples = dataset.load_all()\n",
    "\n",
    "# Extract embeddings and labels\n",
    "embeddings = []\n",
    "all_labels = []\n",
    "for sample in all_samples:\n",
    "    embeddings.append(sample[\"emb\"])\n",
    "    all_labels.append(sample[\"lab\"])\n",
    "\n",
    "embeddings = np.array(embeddings)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(f\"Final fused embeddings: {embeddings.shape}\")\n",
    "print(f\"Labels: {all_labels.shape}\")\n",
    "print(\"DONE! Now we can do MRL on these fused embeddings!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "860b3c3f-9e99-489a-94f3-9909b580d8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: toolz in /home/jupyter-amin/.local/lib/python3.12/site-packages (1.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/tljh/user/lib/python3.12/site-packages (4.66.5)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install toolz tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb9e6cc6-79dc-41e6-81d9-bd345e549de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PY: /mnt/efs/envs/pytorch-env/.venv/bin/python\n",
      "ver: 3.12.6 | packaged by conda-forge | (main, Sep 22 2024, 14:16:49) [GCC 13.3.0]\n",
      "user-site: /home/jupyter-amin/.local/lib/python3.12/site-packages\n",
      "no_user_site flag: 0\n",
      "['/opt/tljh/user/lib/python312.zip',\n",
      " '/opt/tljh/user/lib/python3.12',\n",
      " '/opt/tljh/user/lib/python3.12/lib-dynload',\n",
      " '',\n",
      " '/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys, site, pprint\n",
    "print(\"PY:\", sys.executable)\n",
    "print(\"ver:\", sys.version)\n",
    "print(\"user-site:\", site.getusersitepackages())\n",
    "print(\"no_user_site flag:\", sys.flags.no_user_site)\n",
    "pprint.pprint(sys.path[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adc25de4-0821-40d6-a1cb-be1fdf8cd71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting toolz\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, toolz\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [toolz]\n",
      "\u001b[1A\u001b[2KSuccessfully installed toolz-1.0.0 tqdm-4.67.1\n",
      "\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter-amin/.local/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 107, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "             ^^^^^^^^^^^^\n",
      "  File \"/home/jupyter-amin/.local/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 98, in _inner_run\n",
      "    return self.run(options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jupyter-amin/.local/lib/python3.12/site-packages/pip/_internal/cli/req_command.py\", line 71, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/jupyter-amin/.local/lib/python3.12/site-packages/pip/_internal/commands/install.py\", line 523, in run\n",
      "    self._handle_target_dir(\n",
      "  File \"/home/jupyter-amin/.local/lib/python3.12/site-packages/pip/_internal/commands/install.py\", line 533, in _handle_target_dir\n",
      "    ensure_dir(target_dir)\n",
      "  File \"/home/jupyter-amin/.local/lib/python3.12/site-packages/pip/_internal/utils/misc.py\", line 99, in ensure_dir\n",
      "    os.makedirs(path)\n",
      "  File \"<frozen os>\", line 215, in makedirs\n",
      "  File \"<frozen os>\", line 225, in makedirs\n",
      "PermissionError: [Errno 13] Permission denied: '/team2'\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install --no-cache-dir --target /team2/vendor toolz tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82d39386-2dbb-4fcf-a8ac-a6e43bed7f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/efs/envs/pytorch-env/.venv/bin/python: No module named pip\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['/mnt/efs/envs/pytorch-env/.venv/bin/python', '-m', 'pip', 'install', '--no-cache-dir', '--target', '/home/jupyter-amin/vendor', 'toolz', 'tqdm']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m os.makedirs(VENDOR, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# 2) Install required deps *into that folder*\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-m\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstall\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m--no-cache-dir\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m                       \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m--target\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVENDOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtoolz\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtqdm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 3) Prepend vendor + your data folder(s) to sys.path\u001b[39;00m\n\u001b[32m     12\u001b[39m sys.path.insert(\u001b[32m0\u001b[39m, VENDOR)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/tljh/user/lib/python3.12/subprocess.py:413\u001b[39m, in \u001b[36mcheck_call\u001b[39m\u001b[34m(*popenargs, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cmd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    412\u001b[39m         cmd = popenargs[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, cmd)\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command '['/mnt/efs/envs/pytorch-env/.venv/bin/python', '-m', 'pip', 'install', '--no-cache-dir', '--target', '/home/jupyter-amin/vendor', 'toolz', 'tqdm']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "import sys, os, subprocess\n",
    "\n",
    "# 1) Choose a writable vendor dir in your home\n",
    "VENDOR = \"/home/jupyter-amin/vendor\"\n",
    "os.makedirs(VENDOR, exist_ok=True)\n",
    "\n",
    "# 2) Install required deps *into that folder*\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\",\n",
    "                       \"--target\", VENDOR, \"toolz\", \"tqdm\"])\n",
    "\n",
    "# 3) Prepend vendor + your data folder(s) to sys.path\n",
    "sys.path.insert(0, VENDOR)\n",
    "\n",
    "# Try both common data paths you’ve used\n",
    "for p in [\"/shared/team2/data\", \"/team2/data\"]:\n",
    "    if os.path.isdir(p) and p not in sys.path:\n",
    "        sys.path.insert(0, p)\n",
    "\n",
    "# 4) Sanity checks and your import\n",
    "import toolz, tqdm\n",
    "print(\"toolz:\", toolz.__version__, \"| tqdm:\", tqdm.__version__)\n",
    "\n",
    "from loader import MimicDataset\n",
    "print(\"MimicDataset imported OK ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85ab3bfe-f9de-4f39-bc59-d2d42d6e5169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /tmp/tmp49_9ejnd\n",
      "Requirement already satisfied: pip in /home/jupyter-amin/.local/lib/python3.12/site-packages (25.2)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pip in /home/jupyter-amin/.local/lib/python3.12/site-packages (25.2)\n"
     ]
    }
   ],
   "source": [
    "!python -m ensurepip --upgrade\n",
    "!python -m pip install --upgrade pip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d9df2e4-9a79-4d11-8561-f04f5ed97fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pip at: /opt/tljh/user/bin/pip\n",
      "Installing: /opt/tljh/user/bin/pip install --no-cache-dir --target /home/jupyter-amin/vendor toolz tqdm scikit-learn\n",
      "Collecting toolz\n",
      "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting numpy>=1.22.0 (from scikit-learn)\n",
      "  Downloading numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.16.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (61 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading scikit_learn-1.7.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m198.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Downloading numpy-2.3.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m446.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.16.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m378.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: tqdm, toolz, threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [scikit-learn][0m [scikit-learn]\n",
      "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.1 numpy-2.3.2 scikit-learn-1.7.1 scipy-1.16.1 threadpoolctl-3.6.0 toolz-1.0.0 tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/tqdm-4.67.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/tqdm already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/scipy-1.16.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/scipy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/toolz-1.0.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/threadpoolctl-3.6.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/tlz already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/scipy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/joblib-1.5.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/sklearn already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/scikit_learn.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/joblib already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/scikit_learn-1.7.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/numpy-2.3.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/toolz already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/threadpoolctl.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /home/jupyter-amin/vendor/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toolz: 1.0.0 | tqdm: 4.67.1\n",
      "sklearn: 1.7.1\n",
      "MimicDataset imported OK ✅\n"
     ]
    }
   ],
   "source": [
    "import sys, os, subprocess, shlex\n",
    "\n",
    "# 0) Choose a writable vendor dir\n",
    "VENDOR = os.path.expanduser(\"~/vendor\")\n",
    "os.makedirs(VENDOR, exist_ok=True)\n",
    "\n",
    "# 1) Find a working pip *command* (not python -m pip)\n",
    "candidate_pips = [\n",
    "    \"/opt/tljh/user/bin/pip\",    # common on TLJH/JupyterHub\n",
    "    \"/usr/bin/pip3\",\n",
    "    \"/usr/bin/pip\",\n",
    "    os.path.expanduser(\"~/.local/bin/pip\"),\n",
    "    \"pip3\",\n",
    "    \"pip\",\n",
    "]\n",
    "pip_cmd = None\n",
    "for c in candidate_pips:\n",
    "    try:\n",
    "        out = subprocess.run([c, \"--version\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True, text=True)\n",
    "        pip_cmd = c\n",
    "        break\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "if pip_cmd is None:\n",
    "    raise RuntimeError(\"No working 'pip' executable found in PATH. Try `!apt-get install -y python3-pip` in a shell cell.\")\n",
    "\n",
    "print(f\"Using pip at: {pip_cmd}\")\n",
    "\n",
    "# 2) Install required packages into ~/vendor (no admin rights needed)\n",
    "pkgs = [\"toolz\", \"tqdm\", \"scikit-learn\"]\n",
    "cmd = f\"{shlex.quote(pip_cmd)} install --no-cache-dir --target {shlex.quote(VENDOR)} \" + \" \".join(pkgs)\n",
    "print(\"Installing:\", cmd)\n",
    "subprocess.check_call(cmd, shell=True)\n",
    "\n",
    "# 3) Prepend vendor to sys.path so this kernel can see the packages\n",
    "if VENDOR not in sys.path:\n",
    "    sys.path.insert(0, VENDOR)\n",
    "\n",
    "# 4) (Optional) add your data paths so loader.py is importable\n",
    "for p in [\"/shared/team2/data\", \"/team2/data\"]:\n",
    "    if os.path.isdir(p) and p not in sys.path:\n",
    "        sys.path.insert(0, p)\n",
    "\n",
    "# 5) Sanity checks\n",
    "import toolz, tqdm\n",
    "print(\"toolz:\", toolz.__version__, \"| tqdm:\", tqdm.__version__)\n",
    "try:\n",
    "    import sklearn\n",
    "    print(\"sklearn:\", sklearn.__version__)\n",
    "except Exception as e:\n",
    "    print(\"sklearn not importable yet:\", e)\n",
    "\n",
    "# 6) Try your import now\n",
    "try:\n",
    "    from loader import MimicDataset\n",
    "    print(\"MimicDataset imported OK ✅\")\n",
    "except Exception as e:\n",
    "    print(\"Import failed:\", e)\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e8bb6f4-52e3-489a-b5c0-3a73141a599a",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/home/jupyter-jacob/fsx/embeddings/MIMIC/embds_BiomedCLIP/e13a9fd0-8a30900a-c861a009-5ac3528d-9b82cf09.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m peek_n = \u001b[38;5;28mmin\u001b[39m(\u001b[32m50\u001b[39m, \u001b[38;5;28mlen\u001b[39m(ds))\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(peek_n):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     s = \u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# common label fields\u001b[39;00m\n\u001b[32m     22\u001b[39m     has_label = has_label \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28many\u001b[39m(k \u001b[38;5;129;01min\u001b[39;00m s \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mclass\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/shared/team2/data/loader.py:130\u001b[39m, in \u001b[36mMimicDataset.__getitem__\u001b[39m\u001b[34m(self, i)\u001b[39m\n\u001b[32m    128\u001b[39m sample[\u001b[33m\"\u001b[39m\u001b[33mstudy_id\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m.csv.iloc[i][\u001b[33m\"\u001b[39m\u001b[33mstudy_id\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    129\u001b[39m sample[\u001b[33m\"\u001b[39m\u001b[33mlab\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.labels[i]\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m sample[\u001b[33m\"\u001b[39m\u001b[33memb\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcsv\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdicom_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sample\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/shared/team2/data/loader.py:170\u001b[39m, in \u001b[36mMimicDataset.load_embedding\u001b[39m\u001b[34m(self, embedding_id)\u001b[39m\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.concat(merged_emb)                \n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_dicom_path\u001b[49m\u001b[43m/\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43membds_\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m+\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43membedding_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m/\u001b[49m\u001b[43membedding_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.npy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:454\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    452\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    455\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: '/home/jupyter-jacob/fsx/embeddings/MIMIC/embds_BiomedCLIP/e13a9fd0-8a30900a-c861a009-5ac3528d-9b82cf09.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# --- 1) Load dataset (adjust args if your loader needs them) ---\n",
    "# If your loader needs split/paths/flags, add them here.\n",
    "ds = MimicDataset()\n",
    "\n",
    "# --- 2) Discover embedding fields automatically ---\n",
    "def is_vec(x):\n",
    "    return isinstance(x, np.ndarray) and x.ndim == 1 and x.size > 8\n",
    "\n",
    "# Peek a few samples to find vector-like keys\n",
    "candidate_keys = Counter()\n",
    "has_label = False\n",
    "peek_n = min(50, len(ds))\n",
    "for i in range(peek_n):\n",
    "    s = ds[i]\n",
    "    # common label fields\n",
    "    has_label = has_label or any(k in s for k in (\"label\",\"y\",\"target\",\"class\"))\n",
    "    # count vector-like keys\n",
    "    for k,v in s.items():\n",
    "        if is_vec(v):\n",
    "            candidate_keys[k] += 1\n",
    "\n",
    "# Keep keys that appear in most samples\n",
    "model_keys = [k for k,cnt in candidate_keys.items() if cnt >= max(3, peek_n//4)]\n",
    "if not model_keys:\n",
    "    raise RuntimeError(f\"Could not find embedding keys. Saw keys: {list(candidate_keys.keys())}\")\n",
    "\n",
    "print(\"Detected model embedding keys:\", model_keys)\n",
    "\n",
    "# --- 3) Materialize X per model + labels (if present) ---\n",
    "Xs = {k: [] for k in model_keys}\n",
    "y = []\n",
    "ids = []\n",
    "\n",
    "for i in range(len(ds)):\n",
    "    s = ds[i]\n",
    "    for k in model_keys:\n",
    "        v = s.get(k, None)\n",
    "        if v is None or not is_vec(v):\n",
    "            raise RuntimeError(f\"Sample {i} missing vector for key '{k}'\")\n",
    "        Xs[k].append(v.astype(np.float32))\n",
    "    # labels (best effort)\n",
    "    if \"label\" in s: y.append(s[\"label\"])\n",
    "    elif \"target\" in s: y.append(s[\"target\"])\n",
    "    elif \"y\" in s: y.append(s[\"y\"])\n",
    "    # optional id\n",
    "    if \"id\" in s: ids.append(s[\"id\"])\n",
    "    elif \"uid\" in s: ids.append(s[\"uid\"])\n",
    "\n",
    "for k in model_keys:\n",
    "    Xs[k] = np.stack(Xs[k], axis=0)\n",
    "\n",
    "y = np.array(y) if len(y) == len(ds) else None\n",
    "ids = np.array(ids) if len(ids) == len(ds) else None\n",
    "\n",
    "print({k: Xs[k].shape for k in model_keys})\n",
    "if y is None:\n",
    "    print(\"[INFO] No labels detected; will run retrieval-style checks if needed.\")\n",
    "\n",
    "# --- 4) Blockwise L2 normalization + fused concatenation ---\n",
    "def l2norm(X, eps=1e-12):\n",
    "    n = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    n = np.maximum(n, eps)\n",
    "    return X / n\n",
    "\n",
    "blocks_norm = [l2norm(Xs[k]) for k in model_keys]\n",
    "X_fused = np.concatenate(blocks_norm, axis=1)\n",
    "X_fused = l2norm(X_fused)\n",
    "\n",
    "print(\"Fused shape:\", X_fused.shape)\n",
    "\n",
    "# --- 5) Baselines: per-model vs fused (classification if labels exist) ---\n",
    "def eval_cls_cv(X, y, folds=5):\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    accs, f1s, aucs = [], [], []\n",
    "    multi = (len(np.unique(y)) > 2)\n",
    "    for tr, va in skf.split(X, y):\n",
    "        clf = LogisticRegression(max_iter=5000, n_jobs=None, solver=\"lbfgs\", multi_class=\"auto\")\n",
    "        clf.fit(X[tr], y[tr])\n",
    "        p = clf.predict(X[va])\n",
    "        accs.append(accuracy_score(y[va], p))\n",
    "        f1s.append(f1_score(y[va], p, average=\"weighted\"))\n",
    "        if not multi:\n",
    "            prob = clf.predict_proba(X[va])[:,1]\n",
    "            aucs.append(roc_auc_score(y[va], prob))\n",
    "    out = {\n",
    "        \"acc_mean\": float(np.mean(accs)),\n",
    "        \"acc_std\":  float(np.std(accs)),\n",
    "        \"f1_mean\":  float(np.mean(f1s)),\n",
    "        \"f1_std\":   float(np.std(f1s)),\n",
    "    }\n",
    "    if aucs:\n",
    "        out[\"auc_mean\"] = float(np.mean(aucs))\n",
    "        out[\"auc_std\"]  = float(np.std(aucs))\n",
    "    return out\n",
    "\n",
    "if y is not None:\n",
    "    print(\"\\nSingle-model baselines:\")\n",
    "    for k in model_keys:\n",
    "        res = eval_cls_cv(Xs[k], y)\n",
    "        line = f\"{k:15s} ACC {res['acc_mean']:.3f}±{res['acc_std']:.3f} | F1 {res['f1_mean']:.3f}±{res['f1_std']:.3f}\"\n",
    "        if \"auc_mean\" in res:\n",
    "            line += f\" | AUC {res['auc_mean']:.3f}±{res['auc_std']:.3f}\"\n",
    "        print(line)\n",
    "\n",
    "    print(\"\\nFused (concat, block-L2):\")\n",
    "    res = eval_cls_cv(X_fused, y)\n",
    "    line = f\"{'fused':15s} ACC {res['acc_mean']:.3f}±{res['acc_std']:.3f} | F1 {res['f1_mean']:.3f}±{res['f1_std']:.3f}\"\n",
    "    if \"auc_mean\" in res:\n",
    "        line += f\" | AUC {res['auc_mean']:.3f}±{res['auc_std']:.3f}\"\n",
    "    print(line)\n",
    "\n",
    "# --- 6) MRL-style prefix evaluation on the fused vector ---\n",
    "def prefix_grid(D, base=[128,256,512,1024,2048,4096]):\n",
    "    g = sorted(set([d for d in base if d < D] + [D]))\n",
    "    return g\n",
    "\n",
    "prefixes = prefix_grid(X_fused.shape[1])\n",
    "print(\"\\nMRL-style prefixes:\", prefixes)\n",
    "\n",
    "if y is not None:\n",
    "    print(\"\\nPrefix CV (classification):\")\n",
    "    for D in prefixes:\n",
    "        Xp = X_fused[:, :D]\n",
    "        res = eval_cls_cv(Xp, y)\n",
    "        line = f\"prefix {D:5d} -> ACC {res['acc_mean']:.3f}±{res['acc_std']:.3f} | F1 {res['f1_mean']:.3f}±{res['f1_std']:.3f}\"\n",
    "        if \"auc_mean\" in res:\n",
    "            line += f\" | AUC {res['auc_mean']:.3f}±{res['auc_std']:.3f}\"\n",
    "        print(line)\n",
    "else:\n",
    "    # Simple retrieval proxy: recall@k using cosine on same set (drop self-match)\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    def recall_at_k(X, labels, k=10):\n",
    "        nbrs = NearestNeighbors(n_neighbors=k+1, metric=\"cosine\").fit(X)\n",
    "        idxs = nbrs.kneighbors(X, return_distance=False)\n",
    "        hits = []\n",
    "        for i, neigh in enumerate(idxs):\n",
    "            neigh = neigh[1:]\n",
    "            hits.append(1 if np.any(labels[neigh]==labels[i]) else 0)\n",
    "        return float(np.mean(hits))\n",
    "\n",
    "    # If no labels at all, use coarse pseudo-labels to sanity-check structure\n",
    "    pseudo = np.arange(X_fused.shape[0]) % 10\n",
    "    print(\"\\nPrefix retrieval (recall@10, pseudo-labels):\")\n",
    "    for D in prefixes:\n",
    "        Xp = X_fused[:, :D]\n",
    "        r = recall_at_k(Xp, pseudo, k=10)\n",
    "        print(f\"prefix {D:5d} -> recall@10 {r:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b6753dc-2f4e-4f11-ace4-fea31593e8b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     18\u001b[39m     ds.base_dicom_path = EMB_ROOT\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# ======= 2) FIX THE CHAINED ASSIGNMENT WARNING (SAFE, NO 'self') =======\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# loader.py had:\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# new (safe replacement)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28mself\u001b[39m.csv = \u001b[38;5;28;43mself\u001b[39;49m.csv.copy()\n\u001b[32m     24\u001b[39m \u001b[38;5;28mself\u001b[39m.csv[\u001b[33m\"\u001b[39m\u001b[33mview\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.csv[\u001b[33m\"\u001b[39m\u001b[33mview\u001b[39m\u001b[33m\"\u001b[39m].fillna(\u001b[33m\"\u001b[39m\u001b[33mUNKNOWN\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Do the safe equivalent here (adjust column name if different)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, numpy as np, pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "from loader import MimicDataset\n",
    "\n",
    "# ======= 1) POINT TO A READABLE EMBEDDINGS ROOT =======\n",
    "# Change this to YOUR accessible location containing embds_* folders\n",
    "EMB_ROOT = Path(\"/home/jupyter-amin/fsx/embeddings/MIMIC\")  # <-- EDIT THIS\n",
    "\n",
    "ds = MimicDataset()  # pass args if your loader needs them\n",
    "\n",
    "# If the loader stores a base path, override it:\n",
    "if hasattr(ds, \"base_dicom_path\"):\n",
    "    ds.base_dicom_path = EMB_ROOT\n",
    "\n",
    "# ======= 2) FIX THE CHAINED ASSIGNMENT WARNING (SAFE, NO 'self') =======\n",
    "# loader.py had:\n",
    "# new (safe replacement)\n",
    "self.csv = self.csv.copy()\n",
    "self.csv[\"view\"] = self.csv[\"view\"].fillna(\"UNKNOWN\")\n",
    "\n",
    "# Do the safe equivalent here (adjust column name if different)\n",
    "if hasattr(ds, \"csv\") and \"view\" in ds.csv.columns:\n",
    "    ds.csv = ds.csv.copy()\n",
    "    ds.csv[\"view\"] = ds.csv[\"view\"].fillna(\"UNKNOWN\")\n",
    "\n",
    "\n",
    "# ======= 3) FILTER TO SAMPLES YOU CAN ACTUALLY READ =======\n",
    "# Detect embedding type expected by the loader (or set a default)\n",
    "embedding_type = getattr(ds, \"embedding_type\", None)\n",
    "if embedding_type is None:\n",
    "    embedding_type = \"BiomedCLIP\"  # <-- EDIT if your ds uses another type or \"All\"\n",
    "\n",
    "def path_for(dicom_id, etype=embedding_type):\n",
    "    # matches loader’s npy layout: embds_<type>/<dicom_id>.npy\n",
    "    return EMB_ROOT / f\"embds_{etype}\" / f\"{dicom_id}.npy\"\n",
    "\n",
    "readable_mask = ds.csv[\"dicom_id\"].apply(\n",
    "    lambda x: os.path.isfile(path_for(x)) and os.access(path_for(x), os.R_OK)\n",
    ")\n",
    "n_before = len(ds.csv)\n",
    "ds.csv = ds.csv.loc[readable_mask].reset_index(drop=True)\n",
    "\n",
    "# If your dataset stores labels/aux arrays by index, re-sync them:\n",
    "if hasattr(ds, \"labels\") and len(getattr(ds, \"labels\", [])) == n_before:\n",
    "    ds.labels = np.asarray(ds.labels)[readable_mask.to_numpy()]\n",
    "\n",
    "print(f\"Filtered to readable samples: {len(ds.csv)}/{n_before}\")\n",
    "\n",
    "# ======= 4) MATERIALIZE PER-MODEL EMBEDDINGS =======\n",
    "def load_emb(dicom_id):\n",
    "    p = path_for(dicom_id)\n",
    "    return np.load(p)\n",
    "\n",
    "# Build a single-model matrix first\n",
    "Xs = []\n",
    "for i in range(len(ds.csv)):\n",
    "    Xs.append(load_emb(ds.csv.iloc[i][\"dicom_id\"]).astype(np.float32))\n",
    "X_single = np.vstack(Xs)\n",
    "print(\"Single embedding matrix:\", X_single.shape)\n",
    "\n",
    "# If you want to FUSE four models, list their types and concat if all present\n",
    "MODEL_TYPES = [\"RAD-DINO\", \"MedGemma\", \"CheXagent\", \"BiomedCLIP\"]  # adjust to your dirs\n",
    "blocks, present = [], []\n",
    "for et in MODEL_TYPES:\n",
    "    P = EMB_ROOT / f\"embds_{et}\"\n",
    "    if not P.is_dir():\n",
    "        print(f\"[WARN] Missing dir for {et}: {P}\")\n",
    "        continue\n",
    "    ok = ds.csv[\"dicom_id\"].apply(lambda x: os.path.isfile(P / f\"{x}.npy\"))\n",
    "    if ok.all():\n",
    "        blk = np.vstack([np.load(P / f\"{x}.npy\").astype(np.float32) for x in ds.csv[\"dicom_id\"]])\n",
    "        blocks.append(blk)\n",
    "        present.append(et)\n",
    "    else:\n",
    "        print(f\"[WARN] {et} has missing files; skipping for now to keep alignment clean.\")\n",
    "\n",
    "def l2norm(X, eps=1e-12):\n",
    "    n = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    n = np.maximum(n, eps)\n",
    "    return X / n\n",
    "\n",
    "if blocks:\n",
    "    blocks_norm = [l2norm(b) for b in blocks]\n",
    "    X_fused = np.concatenate(blocks_norm, axis=1)\n",
    "    X_fused = l2norm(X_fused)\n",
    "    print(\"FUSED from models:\", present, \"| shape:\", X_fused.shape)\n",
    "else:\n",
    "    # fallback to single matrix if we couldn’t load multiple blocks\n",
    "    X_fused = l2norm(X_single)\n",
    "    print(\"Using single embedding (normalized) as fused:\", X_fused.shape)\n",
    "\n",
    "# ======= 5) LABELS =======\n",
    "# Try to get labels (adjust to your loader’s field)\n",
    "if hasattr(ds, \"labels\") and len(ds.labels) == len(ds.csv):\n",
    "    y = np.asarray(ds.labels)\n",
    "else:\n",
    "    if \"label\" in ds.csv.columns:\n",
    "        y = ds.csv[\"label\"].to_numpy()\n",
    "    elif \"target\" in ds.csv.columns:\n",
    "        y = ds.csv[\"target\"].to_numpy()\n",
    "    elif \"lab\" in ds.csv.columns:\n",
    "        y = ds.csv[\"lab\"].to_numpy()\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "if y is not None:\n",
    "    print(\"Labels detected:\", np.unique(y, return_counts=True)[0])\n",
    "else:\n",
    "    print(\"[INFO] No labels found; will skip classification metrics.\")\n",
    "\n",
    "# ======= 6) EVALUATION (per MRL prefixes) =======\n",
    "def eval_cls_cv(X, y, folds=5):\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    accs, f1s, aucs = [], [], []\n",
    "    multi = (len(np.unique(y)) > 2)\n",
    "    for tr, va in skf.split(X, y):\n",
    "        clf = LogisticRegression(max_iter=5000, solver=\"lbfgs\", multi_class=\"auto\")\n",
    "        clf.fit(X[tr], y[tr])\n",
    "        p = clf.predict(X[va])\n",
    "        accs.append(accuracy_score(y[va], p))\n",
    "        f1s.append(f1_score(y[va], p, average=\"weighted\"))\n",
    "        if not multi:\n",
    "            prob = clf.predict_proba(X[va])[:, 1]\n",
    "            aucs.append(roc_auc_score(y[va], prob))\n",
    "    out = {\"acc\": (float(np.mean(accs)), float(np.std(accs))),\n",
    "           \"f1\":  (float(np.mean(f1s)),  float(np.std(f1s)))}\n",
    "    if aucs: out[\"auc\"] = (float(np.mean(aucs)), float(np.std(aucs)))\n",
    "    return out\n",
    "\n",
    "def prefix_grid(D, base=[128,256,512,1024,2048,4096]):\n",
    "    return sorted(set([d for d in base if d < D] + [D]))\n",
    "\n",
    "prefixes = prefix_grid(X_fused.shape[1])\n",
    "print(\"MRL-style prefixes:\", prefixes)\n",
    "\n",
    "if y is not None:\n",
    "    for D in prefixes:\n",
    "        Xp = X_fused[:, :D]\n",
    "        res = eval_cls_cv(Xp, y)\n",
    "        msg = f\"prefix {D:5d} -> ACC {res['acc'][0]:.3f}±{res['acc'][1]:.3f} | F1 {res['f1'][0]:.3f}±{res['f1'][1]:.3f}\"\n",
    "        if \"auc\" in res:\n",
    "            msg += f\" | AUC {res['auc'][0]:.3f}±{res['auc'][1]:.3f}\"\n",
    "        print(msg)\n",
    "else:\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    def recall_at_k(X, labels, k=10):\n",
    "        nbrs = NearestNeighbors(n_neighbors=k+1, metric=\"cosine\").fit(X)\n",
    "        idxs = nbrs.kneighbors(X, return_distance=False)\n",
    "        hits = []\n",
    "        for i, neigh in enumerate(idxs):\n",
    "            neigh = neigh[1:]\n",
    "            hits.append(1 if np.any(labels[neigh] == labels[i]) else 0)\n",
    "        return float(np.mean(hits))\n",
    "\n",
    "    pseudo = np.arange(X_fused.shape[0]) % 10\n",
    "    for D in prefixes:\n",
    "        Xp = X_fused[:, :D]\n",
    "        r = recall_at_k(Xp, pseudo, k=10)\n",
    "        print(f\"prefix {D:5d} -> recall@10 {r:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e4edd61-79de-4d82-951e-ef00f5632524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching line found to patch (maybe already fixed).\n",
      "Filtered to readable samples: 27376/27376\n",
      "Single embedding matrix: (27376, 512)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     82\u001b[39m ok = ds.csv[\u001b[33m\"\u001b[39m\u001b[33mdicom_id\u001b[39m\u001b[33m\"\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: os.path.isfile(P / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.npy\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ok.all():\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     blk = np.vstack([\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.npy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m.astype(np.float32) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ds.csv[\u001b[33m\"\u001b[39m\u001b[33mdicom_id\u001b[39m\u001b[33m\"\u001b[39m]])\n\u001b[32m     85\u001b[39m     blocks.append(l2norm(blk))\n\u001b[32m     86\u001b[39m     present.append(et)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:454\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    452\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    455\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === 0) PATCH loader.py IN-PLACE (no manual editing needed) ===\n",
    "from pathlib import Path\n",
    "import re, sys, importlib\n",
    "\n",
    "LOADER_PATH = Path(\"/shared/team2/data/loader.py\")\n",
    "src = LOADER_PATH.read_text()\n",
    "\n",
    "# Replace: self.csv.view.fillna(\"UNKNOWN\", inplace=True)\n",
    "fixed = re.sub(\n",
    "    r'self\\.csv\\.view\\.fillna\\(([\"\\'])UNKNOWN\\1,\\s*inplace=True\\)',\n",
    "    'self.csv = self.csv.copy()\\n        self.csv[\"view\"] = self.csv[\"view\"].fillna(\"UNKNOWN\")',\n",
    "    src,\n",
    "    flags=re.M\n",
    ")\n",
    "\n",
    "if fixed != src:\n",
    "    LOADER_PATH.write_text(fixed)\n",
    "    print(\"Patched loader.py ✅\")\n",
    "else:\n",
    "    print(\"No matching line found to patch (maybe already fixed).\")\n",
    "\n",
    "# Reload (or import) the module\n",
    "if \"loader\" in sys.modules:\n",
    "    importlib.reload(sys.modules[\"loader\"])\n",
    "else:\n",
    "    import loader\n",
    "from loader import MimicDataset\n",
    "\n",
    "# === 1) CONFIG: where your embds_* folders live ===\n",
    "from pathlib import Path\n",
    "import os, numpy as np, pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "EMB_ROOT = Path(\"/home/jupyter-amin/fsx/embeddings/MIMIC\")  # <-- change if needed\n",
    "\n",
    "# === 2) INSTANTIATE DATASET ===\n",
    "ds = MimicDataset()\n",
    "if hasattr(ds, \"base_dicom_path\"):\n",
    "    ds.base_dicom_path = EMB_ROOT\n",
    "\n",
    "# (extra safety: if loader created ds.csv earlier, ensure no chained-assign problems remain)\n",
    "if hasattr(ds, \"csv\") and isinstance(ds.csv, pd.DataFrame) and \"view\" in ds.csv.columns:\n",
    "    ds.csv = ds.csv.copy()\n",
    "    ds.csv[\"view\"] = ds.csv[\"view\"].fillna(\"UNKNOWN\")\n",
    "\n",
    "# === 3) KEEP ONLY READABLE SAMPLES ===\n",
    "embedding_type = getattr(ds, \"embedding_type\", None) or \"BiomedCLIP\"  # edit if needed\n",
    "\n",
    "def path_for(dicom_id, etype=embedding_type):\n",
    "    return EMB_ROOT / f\"embds_{etype}\" / f\"{dicom_id}.npy\"\n",
    "\n",
    "readable_mask = ds.csv[\"dicom_id\"].apply(\n",
    "    lambda x: os.path.isfile(path_for(x)) and os.access(path_for(x), os.R_OK)\n",
    ")\n",
    "n_before = len(ds.csv)\n",
    "ds.csv = ds.csv.loc[readable_mask].reset_index(drop=True)\n",
    "if hasattr(ds, \"labels\") and len(getattr(ds, \"labels\", [])) == n_before:\n",
    "    ds.labels = np.asarray(ds.labels)[readable_mask.to_numpy()]\n",
    "print(f\"Filtered to readable samples: {len(ds.csv)}/{n_before}\")\n",
    "\n",
    "# === 4) LOAD ONE MODEL'S EMBEDDINGS ===\n",
    "def load_emb(dicom_id):\n",
    "    return np.load(path_for(dicom_id)).astype(np.float32)\n",
    "\n",
    "X_single = np.vstack([load_emb(did) for did in ds.csv[\"dicom_id\"]])\n",
    "print(\"Single embedding matrix:\", X_single.shape)\n",
    "\n",
    "# === 5) OPTIONAL: FUSE FOUR MODELS IF PRESENT ===\n",
    "MODEL_TYPES = [\"RAD-DINO\", \"MedGemma\", \"CheXagent\", \"BiomedCLIP\"]  # adjust to what you actually have\n",
    "def l2norm(X, eps=1e-12):\n",
    "    n = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "    return X / np.maximum(n, eps)\n",
    "\n",
    "blocks, present = [], []\n",
    "for et in MODEL_TYPES:\n",
    "    P = EMB_ROOT / f\"embds_{et}\"\n",
    "    if not P.is_dir():\n",
    "        print(f\"[WARN] Missing dir for {et}: {P}\")\n",
    "        continue\n",
    "    ok = ds.csv[\"dicom_id\"].apply(lambda x: os.path.isfile(P / f\"{x}.npy\"))\n",
    "    if ok.all():\n",
    "        blk = np.vstack([np.load(P / f\"{x}.npy\").astype(np.float32) for x in ds.csv[\"dicom_id\"]])\n",
    "        blocks.append(l2norm(blk))\n",
    "        present.append(et)\n",
    "    else:\n",
    "        print(f\"[WARN] {et} has missing files; skipping to keep alignment clean.\")\n",
    "\n",
    "if blocks:\n",
    "    X_fused = np.concatenate(blocks, axis=1)\n",
    "    X_fused = l2norm(X_fused)\n",
    "    print(\"FUSED from models:\", present, \"| shape:\", X_fused.shape)\n",
    "else:\n",
    "    X_fused = l2norm(X_single)\n",
    "    print(\"Using single embedding (normalized) as fused:\", X_fused.shape)\n",
    "\n",
    "# === 6) LABELS ===\n",
    "if hasattr(ds, \"labels\") and len(ds.labels) == len(ds.csv):\n",
    "    y = np.asarray(ds.labels)\n",
    "elif \"label\" in ds.csv.columns:\n",
    "    y = ds.csv[\"label\"].to_numpy()\n",
    "elif \"target\" in ds.csv.columns:\n",
    "    y = ds.csv[\"target\"].to_numpy()\n",
    "elif \"lab\" in ds.csv.columns:\n",
    "    y = ds.csv[\"lab\"].to_numpy()\n",
    "else:\n",
    "    y = None\n",
    "\n",
    "if y is not None:\n",
    "    print(\"Labels detected:\", np.unique(y, return_counts=True)[0])\n",
    "else:\n",
    "    print(\"[INFO] No labels found; skipping classification metrics.\")\n",
    "\n",
    "# === 7) EVAL: MRL-style prefixes ===\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def eval_cls_cv(X, y, folds=5):\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    accs, f1s, aucs = [], [], []\n",
    "    multi = (len(np.unique(y)) > 2)\n",
    "    for tr, va in skf.split(X, y):\n",
    "        clf = LogisticRegression(max_iter=5000, solver=\"lbfgs\", multi_class=\"auto\")\n",
    "        clf.fit(X[tr], y[tr])\n",
    "        p = clf.predict(X[va])\n",
    "        accs.append(accuracy_score(y[va], p))\n",
    "        f1s.append(f1_score(y[va], p, average=\"weighted\"))\n",
    "        if not multi:\n",
    "            prob = clf.predict_proba(X[va])[:, 1]\n",
    "            aucs.append(roc_auc_score(y[va], prob))\n",
    "    out = {\"acc\": (float(np.mean(accs)), float(np.std(accs))),\n",
    "           \"f1\":  (float(np.mean(f1s)),  float(np.std(f1s)))}\n",
    "    if aucs: out[\"auc\"] = (float(np.mean(aucs)), float(np.std(aucs)))\n",
    "    return out\n",
    "\n",
    "def prefix_grid(D, base=[128,256,512,1024,2048,4096]):\n",
    "    return sorted(set([d for d in base if d < D] + [D]))\n",
    "\n",
    "prefixes = prefix_grid(X_fused.shape[1])\n",
    "print(\"MRL-style prefixes:\", prefixes)\n",
    "\n",
    "if y is not None:\n",
    "    for D in prefixes:\n",
    "        Xp = X_fused[:, :D]\n",
    "        res = eval_cls_cv(Xp, y)\n",
    "        msg = f\"prefix {D:5d} -> ACC {res['acc'][0]:.3f}±{res['acc'][1]:.3f} | F1 {res['f1'][0]:.3f}±{res['f1'][1]:.3f}\"\n",
    "        if \"auc\" in res:\n",
    "            msg += f\" | AUC {res['auc'][0]:.3f}±{res['auc'][1]:.3f}\"\n",
    "        print(msg)\n",
    "else:\n",
    "    def recall_at_k(X, labels, k=10):\n",
    "        nbrs = NearestNeighbors(n_neighbors=k+1, metric=\"cosine\").fit(X)\n",
    "        idxs = nbrs.kneighbors(X, return_distance=False)\n",
    "        hits = []\n",
    "        for i, neigh in enumerate(idxs):\n",
    "            neigh = neigh[1:]\n",
    "            hits.append(1 if np.any(labels[neigh] == labels[i]) else 0)\n",
    "        return float(np.mean(hits))\n",
    "    pseudo = np.arange(X_fused.shape[0]) % 10\n",
    "    for D in prefixes:\n",
    "        Xp = X_fused[:, :D]\n",
    "        r = recall_at_k(Xp, pseudo, k=10)\n",
    "        print(f\"prefix {D:5d} -> recall@10 {r:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dce3ca6-7e21-4c9c-b965-7e299d645eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to readable samples: 27376/27376\n",
      "FUSED from models: ['RAD-DINO', 'MedGemma', 'CheXagent', 'BiomedCLIP'] | shape: (27376, 3456)\n",
      "Labels detected: [0. 1.]\n",
      "\n",
      "Single-model baselines:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 109\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSingle-model baselines:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m et, blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(present, blocks):\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     res = \u001b[43meval_cls_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m     line = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00met\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m12s\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> ACC \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33macc_mean\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m±\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33macc_std\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | F1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mf1_mean\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m±\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mf1_std\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mauc_mean\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m res: line += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m | AUC \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mauc_mean\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m±\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[33m'\u001b[39m\u001b[33mauc_std\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36meval_cls_cv\u001b[39m\u001b[34m(X, y, folds)\u001b[39m\n\u001b[32m     85\u001b[39m accs, f1s, aucs = [], [], []\n\u001b[32m     86\u001b[39m multi = (\u001b[38;5;28mlen\u001b[39m(np.unique(y)) > \u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mva\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskf\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mLogisticRegression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlbfgs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vendor/sklearn/model_selection/_split.py:411\u001b[39m, in \u001b[36m_BaseKFold.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m    403\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_splits > n_samples:\n\u001b[32m    404\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    405\u001b[39m         (\n\u001b[32m    406\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mCannot have number of splits n_splits=\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m greater\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    407\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m than the number of samples: n_samples=\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    408\u001b[39m         ).format(\u001b[38;5;28mself\u001b[39m.n_splits, n_samples)\n\u001b[32m    409\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vendor/sklearn/model_selection/_split.py:142\u001b[39m, in \u001b[36mBaseCrossValidator.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m    140\u001b[39m X, y, groups = indexable(X, y, groups)\n\u001b[32m    141\u001b[39m indices = np.arange(_num_samples(X))\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iter_test_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlogical_not\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vendor/sklearn/model_selection/_split.py:844\u001b[39m, in \u001b[36mStratifiedKFold._iter_test_masks\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_iter_test_masks\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m, groups=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m844\u001b[39m     test_folds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_test_folds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.n_splits):\n\u001b[32m    846\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m test_folds == i\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vendor/sklearn/model_selection/_split.py:787\u001b[39m, in \u001b[36mStratifiedKFold._make_test_folds\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    785\u001b[39m allowed_target_types = (\u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m type_of_target_y \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_target_types:\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    788\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSupported target types are: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m. Got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    789\u001b[39m             allowed_target_types, type_of_target_y\n\u001b[32m    790\u001b[39m         )\n\u001b[32m    791\u001b[39m     )\n\u001b[32m    793\u001b[39m y = column_or_1d(y)\n\u001b[32m    795\u001b[39m _, y_idx, y_inv = np.unique(y, return_index=\u001b[38;5;28;01mTrue\u001b[39;00m, return_inverse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: Supported target types are: ('binary', 'multiclass'). Got 'multilabel-indicator' instead."
     ]
    }
   ],
   "source": [
    "# === SET YOUR PATHS ===\n",
    "from pathlib import Path\n",
    "EMB_ROOT = Path(\"/home/jupyter-amin/fsx/embeddings/MIMIC\")  # <-- set to where embds_* live\n",
    "\n",
    "# === IMPORTS ===\n",
    "import os, numpy as np, pandas as pd\n",
    "from loader import MimicDataset\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# === DATASET ===\n",
    "ds = MimicDataset()\n",
    "if hasattr(ds, \"base_dicom_path\"):\n",
    "    ds.base_dicom_path = EMB_ROOT\n",
    "\n",
    "# (safety: if an old ds.csv exists in memory)\n",
    "if hasattr(ds, \"csv\") and \"view\" in ds.csv.columns:\n",
    "    ds.csv = ds.csv.copy()\n",
    "    ds.csv[\"view\"] = ds.csv[\"view\"].fillna(\"UNKNOWN\")\n",
    "\n",
    "# === KEEP ONLY READABLE SAMPLES FOR A DEFAULT MODEL TYPE ===\n",
    "embedding_type = getattr(ds, \"embedding_type\", None) or \"BiomedCLIP\"  # change if needed\n",
    "\n",
    "def path_for(dicom_id, etype=embedding_type):\n",
    "    return EMB_ROOT / f\"embds_{etype}\" / f\"{dicom_id}.npy\"\n",
    "\n",
    "readable_mask = ds.csv[\"dicom_id\"].apply(lambda x: os.path.isfile(path_for(x)) and os.access(path_for(x), os.R_OK))\n",
    "n_before = len(ds.csv)\n",
    "ds.csv = ds.csv.loc[readable_mask].reset_index(drop=True)\n",
    "if hasattr(ds, \"labels\") and len(getattr(ds, \"labels\", [])) == n_before:\n",
    "    ds.labels = np.asarray(ds.labels)[readable_mask.to_numpy()]\n",
    "print(f\"Filtered to readable samples: {len(ds.csv)}/{n_before}\")\n",
    "\n",
    "# === LOAD + FUSE UP TO 4 MODELS ===\n",
    "MODEL_TYPES = [\"RAD-DINO\", \"MedGemma\", \"CheXagent\", \"BiomedCLIP\"]  # adjust to actual dirs\n",
    "\n",
    "def l2norm(X, eps=1e-12):\n",
    "    n = np.linalg.norm(X, axis=1, keepdims=True); n = np.maximum(n, eps); return X / n\n",
    "\n",
    "blocks, present = [], []\n",
    "for et in MODEL_TYPES:\n",
    "    P = EMB_ROOT / f\"embds_{et}\"\n",
    "    if not P.is_dir():\n",
    "        print(f\"[WARN] Missing dir for {et}: {P}\")\n",
    "        continue\n",
    "    ok = ds.csv[\"dicom_id\"].apply(lambda x: os.path.isfile(P / f\"{x}.npy\"))\n",
    "    if ok.all():\n",
    "        blk = np.vstack([np.load(P / f\"{x}.npy\").astype(np.float32) for x in ds.csv[\"dicom_id\"]])\n",
    "        blocks.append(l2norm(blk))\n",
    "        present.append(et)\n",
    "    else:\n",
    "        print(f\"[WARN] {et} has missing files; skipping for alignment.\")\n",
    "\n",
    "if blocks:\n",
    "    X_fused = l2norm(np.concatenate(blocks, axis=1))\n",
    "    print(\"FUSED from models:\", present, \"| shape:\", X_fused.shape)\n",
    "else:\n",
    "    # fallback to the default embedding_type\n",
    "    X_single = np.vstack([np.load(path_for(x)).astype(np.float32) for x in ds.csv[\"dicom_id\"]])\n",
    "    X_fused = l2norm(X_single)\n",
    "    present = [embedding_type]\n",
    "    print(\"Using single embedding (normalized) as fused:\", X_fused.shape)\n",
    "\n",
    "# === LABELS ===\n",
    "if hasattr(ds, \"labels\") and len(ds.labels) == len(ds.csv):\n",
    "    y = np.asarray(ds.labels)\n",
    "elif \"label\" in ds.csv.columns:\n",
    "    y = ds.csv[\"label\"].to_numpy()\n",
    "elif \"target\" in ds.csv.columns:\n",
    "    y = ds.csv[\"target\"].to_numpy()\n",
    "elif \"lab\" in ds.csv.columns:\n",
    "    y = ds.csv[\"lab\"].to_numpy()\n",
    "else:\n",
    "    y = None\n",
    "\n",
    "if y is not None:\n",
    "    print(\"Labels detected:\", np.unique(y, return_counts=True)[0])\n",
    "else:\n",
    "    print(\"[INFO] No labels found; will skip classification metrics.\")\n",
    "\n",
    "# === EVAL HELPERS ===\n",
    "def eval_cls_cv(X, y, folds=5):\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    accs, f1s, aucs = [], [], []\n",
    "    multi = (len(np.unique(y)) > 2)\n",
    "    for tr, va in skf.split(X, y):\n",
    "        clf = LogisticRegression(max_iter=5000, solver=\"lbfgs\", multi_class=\"auto\")\n",
    "        clf.fit(X[tr], y[tr])\n",
    "        p = clf.predict(X[va])\n",
    "        accs.append(accuracy_score(y[va], p))\n",
    "        f1s.append(f1_score(y[va], p, average=\"weighted\"))\n",
    "        if not multi:\n",
    "            prob = clf.predict_proba(X[va])[:, 1]\n",
    "            aucs.append(roc_auc_score(y[va], prob))\n",
    "    out = {\"acc_mean\": float(np.mean(accs)), \"acc_std\": float(np.std(accs)),\n",
    "           \"f1_mean\": float(np.mean(f1s)), \"f1_std\": float(np.std(f1s))}\n",
    "    if aucs: out.update({\"auc_mean\": float(np.mean(aucs)), \"auc_std\": float(np.std(aucs))})\n",
    "    return out\n",
    "\n",
    "def prefix_grid(D, base=[128,256,512,1024,2048,4096]):\n",
    "    return sorted(set([d for d in base if d < D] + [D]))\n",
    "\n",
    "# === PER-MODEL vs FUSED (if multiple blocks are present) ===\n",
    "if y is not None:\n",
    "    if len(present) > 1:\n",
    "        print(\"\\nSingle-model baselines:\")\n",
    "        for et, blk in zip(present, blocks):\n",
    "            res = eval_cls_cv(blk, y)\n",
    "            line = f\"{et:12s} -> ACC {res['acc_mean']:.3f}±{res['acc_std']:.3f} | F1 {res['f1_mean']:.3f}±{res['f1_std']:.3f}\"\n",
    "            if 'auc_mean' in res: line += f\" | AUC {res['auc_mean']:.3f}±{res['auc_std']:.3f}\"\n",
    "            print(line)\n",
    "\n",
    "        print(\"\\nFused:\")\n",
    "        res = eval_cls_cv(X_fused, y)\n",
    "        line = f\"{'fused':12s} -> ACC {res['acc_mean']:.3f}±{res['acc_std']:.3f} | F1 {res['f1_mean']:.3f}±{res['f1_std']:.3f}\"\n",
    "        if 'auc_mean' in res: line += f\" | AUC {res['auc_mean']:.3f}±{res['auc_std']:.3f}\"\n",
    "        print(line)\n",
    "\n",
    "# === MRL-STYLE PREFIX EVAL ===\n",
    "prefixes = prefix_grid(X_fused.shape[1])\n",
    "rows = []\n",
    "print(\"\\nMRL-style prefixes:\", prefixes)\n",
    "\n",
    "if y is not None:\n",
    "    for D in prefixes:\n",
    "        Xp = X_fused[:, :D]\n",
    "        r = eval_cls_cv(Xp, y)\n",
    "        print_str = f\"prefix {D:5d} -> ACC {r['acc_mean']:.3f}±{r['acc_std']:.3f} | F1 {r['f1_mean']:.3f}±{r['f1_std']:.3f}\"\n",
    "        if 'auc_mean' in r: print_str += f\" | AUC {r['auc_mean']:.3f}±{r['auc_std']:.3f}\"\n",
    "        print(print_str)\n",
    "        rows.append({\"prefix_dim\": D, **r})\n",
    "else:\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    def recall_at_k(X, labels, k=10):\n",
    "        nbrs = NearestNeighbors(n_neighbors=k+1, metric=\"cosine\").fit(X)\n",
    "        idxs = nbrs.kneighbors(X, return_distance=False)\n",
    "        hits = []\n",
    "        for i, neigh in enumerate(idxs):\n",
    "            neigh = neigh[1:]\n",
    "            hits.append(1 if np.any(labels[neigh]==labels[i]) else 0)\n",
    "        return float(np.mean(hits))\n",
    "    pseudo = np.arange(X_fused.shape[0]) % 10\n",
    "    for D in prefixes:\n",
    "        Xp = X_fused[:, :D]\n",
    "        r = recall_at_k(Xp, pseudo, k=10)\n",
    "        print(f\"prefix {D:5d} -> recall@10 {r:.3f}\")\n",
    "        rows.append({\"prefix_dim\": D, \"recall@10\": r})\n",
    "\n",
    "# === SAVE RESULTS ===\n",
    "res_df = pd.DataFrame(rows)\n",
    "out_csv = \"/home/jupyter-amin/mrl_prefix_results.csv\"\n",
    "res_df.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fa3170a-94a0-4b4b-8314-5a7b0f1482cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_fused shape: (27376, 3456)\n",
      "dtype: float32\n",
      "min: -0.17022273 max: 0.18780975\n",
      "mean: 6.247042e-05 std: 0.017010232\n",
      "\n",
      "First 3 rows (first 10 dims):\n",
      "[[ 0.004   0.0108 -0.0269  0.0097 -0.0227  0.0041 -0.0028  0.0222  0.0042\n",
      "   0.0046]\n",
      " [ 0.0234 -0.0289  0.0189 -0.0188  0.0184  0.023   0.0312 -0.0143 -0.0105\n",
      "  -0.0163]\n",
      " [ 0.0081  0.0327  0.0047 -0.0021 -0.0085 -0.0259 -0.0189 -0.0075  0.01\n",
      "  -0.0099]]\n",
      "\n",
      "Norm stats: mean 1.0 std 2.1671521e-08\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"X_fused shape:\", X_fused.shape)\n",
    "\n",
    "# basic stats\n",
    "print(\"dtype:\", X_fused.dtype)\n",
    "print(\"min:\", np.min(X_fused), \"max:\", np.max(X_fused))\n",
    "print(\"mean:\", np.mean(X_fused), \"std:\", np.std(X_fused))\n",
    "\n",
    "# look at the first few rows (truncate to first 10 dims for readability)\n",
    "print(\"\\nFirst 3 rows (first 10 dims):\")\n",
    "print(np.round(X_fused[:3, :10], 4))\n",
    "\n",
    "# check L2 norms (should be ~1.0 because we normalized)\n",
    "norms = np.linalg.norm(X_fused, axis=1)\n",
    "print(\"\\nNorm stats: mean\", norms.mean(), \"std\", norms.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f3ef2a0-75be-44bf-9769-0e0032ce2bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27376\n",
      "   subject_id  study_id  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n",
      "0    10897040  58710150          0.0           0.0            0.0    0.0   \n",
      "1    17527057  57149822          0.0           1.0            0.0    0.0   \n",
      "2    17802612  57652627          0.0           0.0            0.0    0.0   \n",
      "3    11616506  59740269          0.0           0.0            0.0    0.0   \n",
      "4    19154373  57438844          0.0           0.0            0.0    1.0   \n",
      "\n",
      "   Enlarged Cardiomediastinum  Fracture  Lung Lesion  Lung Opacity  ...  Rows  \\\n",
      "0                         0.0       0.0          0.0           0.0  ...  3056   \n",
      "1                         0.0       0.0          0.0           0.0  ...  3056   \n",
      "2                         0.0       0.0          0.0           0.0  ...  2544   \n",
      "3                         0.0       0.0          0.0           0.0  ...  3056   \n",
      "4                         0.0       0.0          0.0           1.0  ...  2544   \n",
      "\n",
      "   Columns  StudyDate   StudyTime  ProcedureCodeSequence_CodeMeaning  \\\n",
      "0     2544   21941124  132946.484                 CHEST (PA AND LAT)   \n",
      "1     2544   22020530  233221.046                 CHEST (PA AND LAT)   \n",
      "2     3056   21521003  100944.406                 CHEST (PA AND LAT)   \n",
      "3     2544   21380318  145352.250                 CHEST (PA AND LAT)   \n",
      "4     3056   21840805   50031.515                 CHEST (PA AND LAT)   \n",
      "\n",
      "   ViewCodeSequence_CodeMeaning PatientOrientationCodeSequence_CodeMeaning  \\\n",
      "0              postero-anterior                                      Erect   \n",
      "1              postero-anterior                                      Erect   \n",
      "2              postero-anterior                                      Erect   \n",
      "3              postero-anterior                                      Erect   \n",
      "4              postero-anterior                                      Erect   \n",
      "\n",
      "  view offset_day_int  patient_id  \n",
      "0   PA       21941124    10897040  \n",
      "1   PA       22020530    17527057  \n",
      "2   PA       21521003    17802612  \n",
      "3   PA       21380318    11616506  \n",
      "4   PA       21840805    19154373  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(len(ds.csv))\n",
    "print(ds.csv.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43380067-63f7-4d91-9591-669c96224c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution: (array([-1,  0,  1]), array([  257, 24886,  2233]))\n",
      "\n",
      "Baseline Logistic Regression on fused embeddings for Cardiomegaly:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# --- 3) Run it\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBaseline Logistic Regression on fused embeddings for Cardiomegaly:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43meval_baseline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_fused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36meval_baseline\u001b[39m\u001b[34m(X, y, folds)\u001b[39m\n\u001b[32m     19\u001b[39m     prob = clf.predict_proba(X[va])[:, \u001b[32m1\u001b[39m]\n\u001b[32m     21\u001b[39m     accs.append(accuracy_score(y[va], p))\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     f1s.append(\u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mva\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     23\u001b[39m     aucs.append(roc_auc_score(y[va], prob))\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAccuracy: \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[33m ± \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[33m\"\u001b[39m % (np.mean(accs), np.std(accs)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vendor/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vendor/sklearn/metrics/_classification.py:1465\u001b[39m, in \u001b[36mf1_score\u001b[39m\u001b[34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[39m\n\u001b[32m   1285\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   1286\u001b[39m     {\n\u001b[32m   1287\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msparse matrix\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1312\u001b[39m     zero_division=\u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1313\u001b[39m ):\n\u001b[32m   1314\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[32m   1315\u001b[39m \n\u001b[32m   1316\u001b[39m \u001b[33;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1463\u001b[39m \u001b[33;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[32m   1464\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1472\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1473\u001b[39m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1474\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vendor/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vendor/sklearn/metrics/_classification.py:1683\u001b[39m, in \u001b[36mfbeta_score\u001b[39m\u001b[34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[39m\n\u001b[32m   1477\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   1478\u001b[39m     {\n\u001b[32m   1479\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msparse matrix\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1506\u001b[39m     zero_division=\u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1507\u001b[39m ):\n\u001b[32m   1508\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[32m   1509\u001b[39m \n\u001b[32m   1510\u001b[39m \u001b[33;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1680\u001b[39m \u001b[33;03m    ... )\u001b[39;00m\n\u001b[32m   1681\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1683\u001b[39m     _, _, f, _ = \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1684\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1685\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1686\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1687\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1688\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mf-score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1694\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vendor/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vendor/sklearn/metrics/_classification.py:1996\u001b[39m, in \u001b[36mprecision_recall_fscore_support\u001b[39m\u001b[34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[39m\n\u001b[32m   1827\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[32m   1828\u001b[39m \n\u001b[32m   1829\u001b[39m \u001b[33;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1993\u001b[39m \u001b[33;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[32m   1994\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1995\u001b[39m _check_zero_division(zero_division)\n\u001b[32m-> \u001b[39m\u001b[32m1996\u001b[39m labels = \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1998\u001b[39m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[32m   1999\u001b[39m samplewise = average == \u001b[33m\"\u001b[39m\u001b[33msamples\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/vendor/sklearn/metrics/_classification.py:1779\u001b[39m, in \u001b[36m_check_set_wise_labels\u001b[39m\u001b[34m(y_true, y_pred, average, labels, pos_label)\u001b[39m\n\u001b[32m   1777\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m y_type == \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1778\u001b[39m             average_options.remove(\u001b[33m\"\u001b[39m\u001b[33msamples\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1779\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1780\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m but average=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m\u001b[33m. Please \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1781\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % (y_type, average_options)\n\u001b[32m   1782\u001b[39m         )\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[32m1\u001b[39m):\n\u001b[32m   1784\u001b[39m     warnings.warn(\n\u001b[32m   1785\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) is ignored when \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1786\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maverage != \u001b[39m\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m\u001b[33m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m). You may use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1789\u001b[39m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m   1790\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# --- 1) Select the label column\n",
    "y = ds.csv[\"Cardiomegaly\"].astype(int).to_numpy()\n",
    "print(\"Target distribution:\", np.unique(y, return_counts=True))\n",
    "\n",
    "# --- 2) Cross-validated logistic regression baseline\n",
    "def eval_baseline(X, y, folds=5):\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    accs, f1s, aucs = [], [], []\n",
    "\n",
    "    for tr, va in skf.split(X, y):\n",
    "        clf = LogisticRegression(max_iter=5000, solver=\"lbfgs\", class_weight=\"balanced\")\n",
    "        clf.fit(X[tr], y[tr])\n",
    "        p = clf.predict(X[va])\n",
    "        prob = clf.predict_proba(X[va])[:, 1]\n",
    "\n",
    "        accs.append(accuracy_score(y[va], p))\n",
    "        f1s.append(f1_score(y[va], p))\n",
    "        aucs.append(roc_auc_score(y[va], prob))\n",
    "\n",
    "    print(\"Accuracy: %.3f ± %.3f\" % (np.mean(accs), np.std(accs)))\n",
    "    print(\"F1-score: %.3f ± %.3f\" % (np.mean(f1s), np.std(f1s)))\n",
    "    print(\"ROC-AUC:  %.3f ± %.3f\" % (np.mean(aucs), np.std(aucs)))\n",
    "\n",
    "# --- 3) Run it\n",
    "print(\"\\nBaseline Logistic Regression on fused embeddings for Cardiomegaly:\")\n",
    "eval_baseline(X_fused, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b86ee6fc-d6d4-4b50-bdf8-033c41c59361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution after dropping -1: (array([0, 1]), array([24886,  2233]))\n",
      "\n",
      "Baseline Logistic Regression on fused embeddings for Cardiomegaly (0 vs 1 only):\n",
      "Accuracy: 0.826 ± 0.003\n",
      "F1-score: 0.439 ± 0.006\n",
      "ROC-AUC:  0.903 ± 0.005\n"
     ]
    }
   ],
   "source": [
    "# --- 1) Select label and drop uncertain cases\n",
    "mask = ds.csv[\"Cardiomegaly\"] != -1\n",
    "X_clean = X_fused[mask]\n",
    "y_clean = ds.csv.loc[mask, \"Cardiomegaly\"].astype(int).to_numpy()\n",
    "\n",
    "print(\"Target distribution after dropping -1:\", np.unique(y_clean, return_counts=True))\n",
    "\n",
    "# --- 2) Evaluation with only 0 vs 1\n",
    "def eval_baseline(X, y, folds=5):\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    accs, f1s, aucs = [], [], []\n",
    "\n",
    "    for tr, va in skf.split(X, y):\n",
    "        clf = LogisticRegression(max_iter=5000, solver=\"lbfgs\", class_weight=\"balanced\")\n",
    "        clf.fit(X[tr], y[tr])\n",
    "        p = clf.predict(X[va])\n",
    "        prob = clf.predict_proba(X[va])[:, 1]\n",
    "\n",
    "        accs.append(accuracy_score(y[va], p))\n",
    "        f1s.append(f1_score(y[va], p))  # now binary\n",
    "        aucs.append(roc_auc_score(y[va], prob))\n",
    "\n",
    "    print(\"Accuracy: %.3f ± %.3f\" % (np.mean(accs), np.std(accs)))\n",
    "    print(\"F1-score: %.3f ± %.3f\" % (np.mean(f1s), np.std(f1s)))\n",
    "    print(\"ROC-AUC:  %.3f ± %.3f\" % (np.mean(aucs), np.std(aucs)))\n",
    "\n",
    "print(\"\\nBaseline Logistic Regression on fused embeddings for Cardiomegaly (0 vs 1 only):\")\n",
    "eval_baseline(X_clean, y_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca55e6ef-d727-468f-8447-a9e23980cc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardiomegaly distribution (0 vs 1): (array([0, 1]), array([24886,  2233]))\n",
      "Prefix dims: [128, 256, 512, 768, 1024, 1536, 2048, 3072, 3456]\n",
      "prefix  128 -> ACC 0.761±0.002 | F1 0.343±0.004 | AUC 0.829±0.008\n",
      "prefix  256 -> ACC 0.775±0.003 | F1 0.364±0.005 | AUC 0.856±0.008\n",
      "prefix  512 -> ACC 0.794±0.005 | F1 0.388±0.007 | AUC 0.872±0.007\n",
      "prefix  768 -> ACC 0.800±0.003 | F1 0.398±0.009 | AUC 0.878±0.008\n",
      "prefix 1024 -> ACC 0.811±0.001 | F1 0.414±0.009 | AUC 0.888±0.008\n",
      "prefix 1536 -> ACC 0.814±0.002 | F1 0.417±0.008 | AUC 0.889±0.008\n",
      "prefix 2048 -> ACC 0.819±0.003 | F1 0.427±0.005 | AUC 0.895±0.007\n",
      "prefix 3072 -> ACC 0.825±0.002 | F1 0.438±0.006 | AUC 0.903±0.005\n",
      "prefix 3456 -> ACC 0.826±0.003 | F1 0.439±0.006 | AUC 0.903±0.005\n",
      "Saved: /home/jupyter-amin/mrl_prefix_results_cardiomegaly.csv\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# 0) PREP: labels (drop -1)\n",
    "# ----------------------------\n",
    "label_name = \"Cardiomegaly\"\n",
    "mask = ds.csv[label_name] != -1\n",
    "X = X_fused[mask]\n",
    "y = ds.csv.loc[mask, label_name].astype(int).to_numpy()\n",
    "print(f\"{label_name} distribution (0 vs 1):\", np.unique(y, return_counts=True))\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Prefix grid\n",
    "# ----------------------------\n",
    "D_full = X.shape[1]\n",
    "# choose a reasonable grid up to full dim\n",
    "base = [128, 256, 512, 768, 1024, 1536, 2048, 3072, D_full]\n",
    "prefixes = sorted(set([d for d in base if d <= D_full] + [D_full]))\n",
    "print(\"Prefix dims:\", prefixes)\n",
    "\n",
    "# ----------------------------\n",
    "# 2) CV eval function\n",
    "# ----------------------------\n",
    "def eval_cv_logreg(Xp, y, folds=5):\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    accs, f1s, aucs = [], [], []\n",
    "    for tr, va in skf.split(Xp, y):\n",
    "        clf = LogisticRegression(max_iter=5000, solver=\"lbfgs\", class_weight=\"balanced\")\n",
    "        clf.fit(Xp[tr], y[tr])\n",
    "        p = clf.predict(Xp[va])\n",
    "        prob = clf.predict_proba(Xp[va])[:, 1]\n",
    "        accs.append(accuracy_score(y[va], p))\n",
    "        f1s.append(f1_score(y[va], p))\n",
    "        aucs.append(roc_auc_score(y[va], prob))\n",
    "    return {\n",
    "        \"acc_mean\": float(np.mean(accs)), \"acc_std\": float(np.std(accs)),\n",
    "        \"f1_mean\":  float(np.mean(f1s)),  \"f1_std\":  float(np.std(f1s)),\n",
    "        \"auc_mean\": float(np.mean(aucs)), \"auc_std\": float(np.std(aucs)),\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Run prefixes\n",
    "# ----------------------------\n",
    "rows = []\n",
    "for D in prefixes:\n",
    "    Xp = X[:, :D]\n",
    "    res = eval_cv_logreg(Xp, y, folds=5)\n",
    "    rows.append({\"prefix_dim\": D, **res})\n",
    "    print(f\"prefix {D:4d} -> ACC {res['acc_mean']:.3f}±{res['acc_std']:.3f} | \"\n",
    "          f\"F1 {res['f1_mean']:.3f}±{res['f1_std']:.3f} | \"\n",
    "          f\"AUC {res['auc_mean']:.3f}±{res['auc_std']:.3f}\")\n",
    "\n",
    "res_df = pd.DataFrame(rows).sort_values(\"prefix_dim\")\n",
    "out_csv = \"/home/jupyter-amin/mrl_prefix_results_cardiomegaly.csv\"\n",
    "res_df.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv)\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Quick plots\n",
    "# ----------------------------\n",
    "plt.figure()\n",
    "plt.plot(res_df[\"prefix_dim\"], res_df[\"auc_mean\"], marker=\"o\")\n",
    "plt.xlabel(\"Prefix dimension\")\n",
    "plt.ylabel(\"ROC-AUC (mean CV)\")\n",
    "plt.title(f\"MRL-style prefix curve: {label_name}\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(res_df[\"prefix_dim\"], res_df[\"f1_mean\"], marker=\"o\")\n",
    "plt.xlabel(\"Prefix dimension\")\n",
    "plt.ylabel(\"F1 (mean CV)\")\n",
    "plt.title(f\"MRL-style prefix curve (F1): {label_name}\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76f2cb71-12b1-4108-92cd-5f1b340bf4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda | N: 27119 | D: 3456 | Pos: 2233 | Neg: 24886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_118091/2821423089.py:55: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(amp and device.type==\"cuda\"))\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "Caught AcceleratorError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/dataset.py\", line 207, in __getitem__\n    return tuple(tensor[index] for tensor in self.tensors)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/dataset.py\", line 207, in <genexpr>\n    return tuple(tensor[index] for tensor in self.tensors)\n                 ~~~~~~^^^^^^^\ntorch.AcceleratorError: CUDA error: initialization error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 87\u001b[39m\n\u001b[32m     85\u001b[39m rows = []\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m D \u001b[38;5;129;01min\u001b[39;00m prefixes:\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     (acc_m, acc_s), (f1_m, f1_s), (auc_m, auc_s) = \u001b[43mtrain_eval_prefix\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mamp\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_amp\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprefix \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mD\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m4d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -> ACC \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m±\u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc_s\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | F1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m±\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_s\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | AUC \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc_m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m±\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc_s\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     91\u001b[39m     rows.append({\u001b[33m\"\u001b[39m\u001b[33mprefix_dim\u001b[39m\u001b[33m\"\u001b[39m: D, \u001b[33m\"\u001b[39m\u001b[33macc_mean\u001b[39m\u001b[33m\"\u001b[39m: acc_m, \u001b[33m\"\u001b[39m\u001b[33macc_std\u001b[39m\u001b[33m\"\u001b[39m: acc_s,\n\u001b[32m     92\u001b[39m                  \u001b[33m\"\u001b[39m\u001b[33mf1_mean\u001b[39m\u001b[33m\"\u001b[39m: f1_m, \u001b[33m\"\u001b[39m\u001b[33mf1_std\u001b[39m\u001b[33m\"\u001b[39m: f1_s, \u001b[33m\"\u001b[39m\u001b[33mauc_mean\u001b[39m\u001b[33m\"\u001b[39m: auc_m, \u001b[33m\"\u001b[39m\u001b[33mauc_std\u001b[39m\u001b[33m\"\u001b[39m: auc_s})\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mtrain_eval_prefix\u001b[39m\u001b[34m(X_np, y_np, D, folds, epochs, batch, lr, wd, amp)\u001b[39m\n\u001b[32m     58\u001b[39m model.train()\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdl\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mset_to_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mamp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautocast\u001b[49m\u001b[43m(\u001b[49m\u001b[43menabled\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\u001b[43m==\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1516\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1514\u001b[39m worker_id = \u001b[38;5;28mself\u001b[39m._task_info.pop(idx)[\u001b[32m0\u001b[39m]\n\u001b[32m   1515\u001b[39m \u001b[38;5;28mself\u001b[39m._rcvd_idx += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1516\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1551\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data, worker_idx)\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1551\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/_utils.py:769\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    766\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[32m    767\u001b[39m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    768\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mAcceleratorError\u001b[39m: Caught AcceleratorError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/dataset.py\", line 207, in __getitem__\n    return tuple(tensor[index] for tensor in self.tensors)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/dataset.py\", line 207, in <genexpr>\n    return tuple(tensor[index] for tensor in self.tensors)\n                 ~~~~~~^^^^^^^\ntorch.AcceleratorError: CUDA error: initialization error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": [
    "# === GPU-accelerated prefix evaluation (Cardiomegaly) ===\n",
    "import numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# -------- Config (tune for speed/quality) --------\n",
    "label_name   = \"Cardiomegaly\"\n",
    "folds        = 3          # 3 is fast; use 5 for final\n",
    "epochs       = 4          # bump to 8–10 if still fast\n",
    "batch_size   = 8192       # increase if GPU has memory (e.g., 16384)\n",
    "lr           = 1e-2\n",
    "weight_decay = 1e-4\n",
    "use_amp      = True       # mixed precision on GPU\n",
    "# Choose a compact prefix grid to start; expand later if you want\n",
    "prefixes     = [128, 256, 512, 1024, 1536, 2048, 3072]  # full will be appended below\n",
    "\n",
    "# -------- Prep data (drop -1 uncertain) --------\n",
    "mask = ds.csv[label_name] != -1\n",
    "X = X_fused[mask].astype(np.float32)\n",
    "y = ds.csv.loc[mask, label_name].astype(int).to_numpy().astype(np.float32)\n",
    "\n",
    "D_full = X.shape[1]\n",
    "if prefixes[-1] != D_full:\n",
    "    prefixes = [d for d in prefixes if d <= D_full] + [D_full]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device, \"| N:\", X.shape[0], \"| D:\", D_full, \"| Pos:\", int(y.sum()), \"| Neg:\", int((1-y).sum()))\n",
    "\n",
    "# -------- Tiny logistic head (single linear layer) --------\n",
    "class LogReg(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(dim, 1)\n",
    "    def forward(self, x):\n",
    "        return self.fc(x).squeeze(1)  # logits\n",
    "\n",
    "def train_eval_prefix(X_np, y_np, D, folds=3, epochs=4, batch=8192, lr=1e-2, wd=1e-4, amp=True):\n",
    "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    accs, f1s, aucs = [], [], []\n",
    "    pos_weight_val = (len(y_np) - y_np.sum()) / (y_np.sum() + 1e-9)  # handle imbalance\n",
    "    pos_weight = torch.tensor(pos_weight_val, dtype=torch.float32, device=device)\n",
    "\n",
    "    for tr_idx, va_idx in skf.split(X_np, y_np.astype(int)):\n",
    "        Xtr = torch.from_numpy(X_np[tr_idx, :D]).to(device, non_blocking=True)\n",
    "        Xva = torch.from_numpy(X_np[va_idx, :D]).to(device, non_blocking=True)\n",
    "        ytr = torch.from_numpy(y_np[tr_idx]).to(device, non_blocking=True)\n",
    "        yva = torch.from_numpy(y_np[va_idx]).to(device, non_blocking=True)\n",
    "\n",
    "        dl = DataLoader(TensorDataset(Xtr, ytr), batch_size=batch, shuffle=True,\n",
    "                        pin_memory=(device.type==\"cuda\"), num_workers=2, persistent_workers=False)\n",
    "\n",
    "        model = LogReg(D).to(device)\n",
    "        opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "        scaler = torch.cuda.amp.GradScaler(enabled=(amp and device.type==\"cuda\"))\n",
    "        loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "        model.train()\n",
    "        for _ in range(epochs):\n",
    "            for xb, yb in dl:\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                with torch.cuda.amp.autocast(enabled=(amp and device.type==\"cuda\")):\n",
    "                    logits = model(xb)\n",
    "                    loss = loss_fn(logits, yb)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(opt)\n",
    "                scaler.update()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(Xva)\n",
    "            probs = torch.sigmoid(logits).float().cpu().numpy()\n",
    "            pred  = (probs >= 0.5).astype(np.int32)\n",
    "            ytrue = yva.float().cpu().numpy().astype(np.int32)\n",
    "\n",
    "        accs.append(accuracy_score(ytrue, pred))\n",
    "        f1s.append(f1_score(ytrue, pred))\n",
    "        aucs.append(roc_auc_score(ytrue, probs))\n",
    "\n",
    "    return (float(np.mean(accs)), float(np.std(accs))), \\\n",
    "           (float(np.mean(f1s)),  float(np.std(f1s))),  \\\n",
    "           (float(np.mean(aucs)), float(np.std(aucs)))\n",
    "\n",
    "# -------- Run the prefixes --------\n",
    "rows = []\n",
    "for D in prefixes:\n",
    "    (acc_m, acc_s), (f1_m, f1_s), (auc_m, auc_s) = train_eval_prefix(\n",
    "        X, y, D, folds=folds, epochs=epochs, batch=batch_size, lr=lr, wd=weight_decay, amp=use_amp\n",
    "    )\n",
    "    print(f\"prefix {D:4d} -> ACC {acc_m:.3f}±{acc_s:.3f} | F1 {f1_m:.3f}±{f1_s:.3f} | AUC {auc_m:.3f}±{auc_s:.3f}\")\n",
    "    rows.append({\"prefix_dim\": D, \"acc_mean\": acc_m, \"acc_std\": acc_s,\n",
    "                 \"f1_mean\": f1_m, \"f1_std\": f1_s, \"auc_mean\": auc_m, \"auc_std\": auc_s})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73bb434e-9ee4-4856-8bfc-0f5e7740fc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_118091/2821423089.py:55: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(amp and device.type==\"cuda\"))\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "Caught AcceleratorError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/dataset.py\", line 207, in __getitem__\n    return tuple(tensor[index] for tensor in self.tensors)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/dataset.py\", line 207, in <genexpr>\n    return tuple(tensor[index] for tensor in self.tensors)\n                 ~~~~~~^^^^^^^\ntorch.AcceleratorError: CUDA error: initialization error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m scan_prefixes = [d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m scan_prefixes \u001b[38;5;28;01mif\u001b[39;00m d <= D_full]\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 1) get full AUC at D_full (or reuse if you already printed it)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m (_, _), (_, _), (full_auc, full_auc_std) = \u001b[43mtrain_eval_prefix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFull AUC @ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mD_full\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_auc_std\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 2) sweep smaller prefixes and collect metrics\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mtrain_eval_prefix\u001b[39m\u001b[34m(X_np, y_np, D, folds, epochs, batch, lr, wd, amp)\u001b[39m\n\u001b[32m     58\u001b[39m model.train()\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdl\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mset_to_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mamp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautocast\u001b[49m\u001b[43m(\u001b[49m\u001b[43menabled\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\u001b[43m==\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1516\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1514\u001b[39m worker_id = \u001b[38;5;28mself\u001b[39m._task_info.pop(idx)[\u001b[32m0\u001b[39m]\n\u001b[32m   1515\u001b[39m \u001b[38;5;28mself\u001b[39m._rcvd_idx += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1516\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1551\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._process_data\u001b[39m\u001b[34m(self, data, worker_idx)\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28mself\u001b[39m._try_put_index()\n\u001b[32m   1550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[32m-> \u001b[39m\u001b[32m1551\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/_utils.py:769\u001b[39m, in \u001b[36mExceptionWrapper.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    765\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    766\u001b[39m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[32m    767\u001b[39m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[32m    768\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[31mAcceleratorError\u001b[39m: Caught AcceleratorError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/dataset.py\", line 207, in __getitem__\n    return tuple(tensor[index] for tensor in self.tensors)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/utils/data/dataset.py\", line 207, in <genexpr>\n    return tuple(tensor[index] for tensor in self.tensors)\n                 ~~~~~~^^^^^^^\ntorch.AcceleratorError: CUDA error: initialization error\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- config ---\n",
    "tol_pct = 0.02   # 2% within full AUC; set 0.01 for 1%\n",
    "scan_prefixes = [128, 256, 512, 768, 1024, 1536, 2048, 3072, D_full]\n",
    "scan_prefixes = [d for d in scan_prefixes if d <= D_full]\n",
    "\n",
    "# 1) get full AUC at D_full (or reuse if you already printed it)\n",
    "(_, _), (_, _), (full_auc, full_auc_std) = train_eval_prefix(X, y, D_full, folds=3, epochs=4)\n",
    "print(f\"Full AUC @ {D_full} = {full_auc:.3f} ± {full_auc_std:.3f}\")\n",
    "\n",
    "# 2) sweep smaller prefixes and collect metrics\n",
    "rows = []\n",
    "for D in scan_prefixes:\n",
    "    (acc_m, acc_s), (f1_m, f1_s), (auc_m, auc_s) = train_eval_prefix(X, y, D, folds=3, epochs=4)\n",
    "    rows.append({\"prefix_dim\": D, \"acc_mean\": acc_m, \"acc_std\": acc_s,\n",
    "                 \"f1_mean\": f1_m, \"f1_std\": f1_s, \"auc_mean\": auc_m, \"auc_std\": auc_s})\n",
    "    print(f\"prefix {D:4d} -> AUC {auc_m:.3f}±{auc_s:.3f} | F1 {f1_m:.3f}±{f1_s:.3f} | ACC {acc_m:.3f}±{acc_s:.3f}\")\n",
    "\n",
    "res = pd.DataFrame(rows).sort_values(\"prefix_dim\").reset_index(drop=True)\n",
    "\n",
    "# 3) pick D* : smallest D with AUC >= (1 - tol_pct) * full_auc\n",
    "threshold = (1.0 - tol_pct) * full_auc\n",
    "candidates = res[res[\"auc_mean\"] >= threshold]\n",
    "if len(candidates) == 0:\n",
    "    D_star = int(res.iloc[-1][\"prefix_dim\"])  # fallback to full\n",
    "else:\n",
    "    D_star = int(candidates.iloc[0][\"prefix_dim\"])\n",
    "\n",
    "print(f\"\\n>> D* (within {tol_pct*100:.0f}% of full AUC): {D_star}  (threshold AUC >= {threshold:.3f})\")\n",
    "\n",
    "# 4) save the table and D*\n",
    "out_csv = \"/home/jupyter-amin/mrl_prefix_results_cardiomegaly_gpu.csv\"\n",
    "res.to_csv(out_csv, index=False)\n",
    "with open(\"/home/jupyter-amin/mrl_D_star.txt\", \"w\") as f:\n",
    "    f.write(str(D_star))\n",
    "print(\"Saved results to:\", out_csv)\n",
    "print(\"Saved D* to:     /home/jupyter-amin/mrl_D_star.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3f4d15a-d1e6-49c1-a8ac-b504d2fb62a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "N: 27119 | D_full: 3456 | Pos: 2233 | Neg: 24886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_118091/433340811.py:49: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(use_amp and device.type==\"cuda\"))\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:49: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(use_amp and device.type==\"cuda\"))\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:49: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(use_amp and device.type==\"cuda\"))\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:49: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(use_amp and device.type==\"cuda\"))\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:49: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(use_amp and device.type==\"cuda\"))\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full AUC @ 3456: 0.881 ± 0.004\n",
      "AUC threshold for D*: 0.864 (within 2% of full)\n",
      "prefix  128 -> AUC 0.691±0.022 | F1 0.140±0.106 | ACC 0.615±0.304\n",
      "prefix  256 -> AUC 0.773±0.007 | F1 0.271±0.040 | ACC 0.687±0.178\n",
      "prefix  512 -> AUC 0.820±0.007 | F1 0.308±0.005 | ACC 0.707±0.008\n",
      "prefix  768 -> AUC 0.838±0.011 | F1 0.324±0.025 | ACC 0.720±0.044\n",
      "prefix 1024 -> AUC 0.863±0.004 | F1 0.379±0.013 | ACC 0.788±0.024\n",
      "prefix 1536 -> AUC 0.867±0.002 | F1 0.394±0.010 | ACC 0.811±0.015\n",
      ">> EARLY STOP: D* = 1536 (meets threshold)\n",
      "Saved: /home/jupyter-amin/mrl_prefix_results_cardiomegaly_gpu_fast.csv\n",
      "D* saved to /home/jupyter-amin/mrl_D_star.txt  -> 1536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:49: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(use_amp and device.type==\"cuda\"))\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:49: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(use_amp and device.type==\"cuda\"))\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
      "/tmp/ipykernel_118091/433340811.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n"
     ]
    }
   ],
   "source": [
    "# ==== FAST GPU PREFIX SCAN WITH EARLY STOP ====\n",
    "import numpy as np, torch, torch.nn as nn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# ----- config -----\n",
    "label_name   = \"Cardiomegaly\"\n",
    "folds        = 3\n",
    "epochs       = 3          # small for quick scan; bump later for final numbers\n",
    "batch_size   = 16384      # increase if GPU RAM allows; try 32768 if you can\n",
    "lr           = 1e-2\n",
    "weight_decay = 1e-4\n",
    "use_amp      = True\n",
    "tol_pct      = 0.02       # within 2% of full AUC\n",
    "scan_prefixes = [128, 256, 512, 768, 1024, 1536, 2048, 3072]  # full will be appended\n",
    "\n",
    "# ----- prep (drop -1) -----\n",
    "mask = ds.csv[label_name] != -1\n",
    "X_np = X_fused[mask].astype(np.float32)\n",
    "y_np = ds.csv.loc[mask, label_name].astype(int).to_numpy().astype(np.float32)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "if device.type != \"cuda\":\n",
    "    print(\"NOTE: CUDA not visible to PyTorch; this will run on CPU and be slower.\")\n",
    "\n",
    "N, D_full = X_np.shape\n",
    "if scan_prefixes[-1] != D_full:\n",
    "    scan_prefixes = [d for d in scan_prefixes if d <= D_full] + [D_full]\n",
    "print(\"N:\", N, \"| D_full:\", D_full, \"| Pos:\", int(y_np.sum()), \"| Neg:\", int((1-y_np).sum()))\n",
    "\n",
    "# Move all data once to GPU; we'll slice prefixes as views\n",
    "X_gpu = torch.from_numpy(X_np).to(device, non_blocking=True)\n",
    "y_gpu = torch.from_numpy(y_np).to(device, non_blocking=True)\n",
    "\n",
    "# Pre-compute CV splits once and reuse\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "splits = list(skf.split(np.zeros(N), y_np.astype(int)))  # y for stratification only\n",
    "\n",
    "# Tiny logistic head\n",
    "class LogReg(nn.Module):\n",
    "    def __init__(self, dim): super().__init__(); self.fc = nn.Linear(dim, 1)\n",
    "    def forward(self, x):    return self.fc(x).squeeze(1)  # logits\n",
    "\n",
    "def run_auc_for_dim(D, epochs=3):\n",
    "    accs, f1s, aucs = [], [], []\n",
    "    pos_weight_val = (len(y_np) - y_np.sum()) / (y_np.sum() + 1e-9)\n",
    "    pos_weight = torch.tensor(pos_weight_val, dtype=torch.float32, device=device)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(use_amp and device.type==\"cuda\"))\n",
    "\n",
    "    for tr_idx, va_idx in splits:\n",
    "        Xtr = X_gpu[tr_idx, :D]\n",
    "        Xva = X_gpu[va_idx, :D]\n",
    "        ytr = y_gpu[tr_idx]\n",
    "        yva = y_gpu[va_idx]\n",
    "\n",
    "        model = LogReg(D).to(device)\n",
    "        opt   = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "        # train\n",
    "        model.train()\n",
    "        # simple big-batch loop (no dataloader to avoid overhead)\n",
    "        for _ in range(epochs):\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=(use_amp and device.type==\"cuda\")):\n",
    "                logits = model(Xtr)\n",
    "                loss = loss_fn(logits, ytr)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "\n",
    "        # eval\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            probs = torch.sigmoid(model(Xva)).float().cpu().numpy()\n",
    "            pred  = (probs >= 0.5).astype(np.int32)\n",
    "            ytrue = yva.float().cpu().numpy().astype(np.int32)\n",
    "\n",
    "        accs.append(accuracy_score(ytrue, pred))\n",
    "        f1s.append(f1_score(ytrue, pred))\n",
    "        aucs.append(roc_auc_score(ytrue, probs))\n",
    "\n",
    "    return (float(np.mean(accs)), float(np.std(accs))), \\\n",
    "           (float(np.mean(f1s)),  float(np.std(f1s))),  \\\n",
    "           (float(np.mean(aucs)), float(np.std(aucs)))\n",
    "\n",
    "# 1) Get full AUC once\n",
    "(_, _), (_, _), (full_auc, full_auc_std) = run_auc_for_dim(D_full, epochs=max(epochs, 4))\n",
    "print(f\"Full AUC @ {D_full}: {full_auc:.3f} ± {full_auc_std:.3f}\")\n",
    "threshold = (1.0 - tol_pct) * full_auc\n",
    "print(f\"AUC threshold for D*: {threshold:.3f} (within {int(tol_pct*100)}% of full)\")\n",
    "\n",
    "# 2) Scan small -> big, stop at first that meets threshold\n",
    "rows = []\n",
    "D_star = None\n",
    "for D in scan_prefixes:\n",
    "    (acc_m, acc_s), (f1_m, f1_s), (auc_m, auc_s) = run_auc_for_dim(D, epochs=epochs)\n",
    "    rows.append({\"prefix_dim\": D, \"acc_mean\": acc_m, \"acc_std\": acc_s,\n",
    "                 \"f1_mean\": f1_m, \"f1_std\": f1_s, \"auc_mean\": auc_m, \"auc_std\": auc_s})\n",
    "    print(f\"prefix {D:4d} -> AUC {auc_m:.3f}±{auc_s:.3f} | F1 {f1_m:.3f}±{f1_s:.3f} | ACC {acc_m:.3f}±{acc_s:.3f}\")\n",
    "    if D_star is None and auc_m >= threshold:\n",
    "        D_star = D\n",
    "        print(f\">> EARLY STOP: D* = {D_star} (meets threshold)\")\n",
    "        break\n",
    "\n",
    "if D_star is None:\n",
    "    D_star = D_full\n",
    "    print(f\">> No prefix met threshold; using D* = full ({D_full}).\")\n",
    "\n",
    "# 3) Save results and D*\n",
    "import pandas as pd, os\n",
    "res_df = pd.DataFrame(rows)\n",
    "os.makedirs(\"/home/jupyter-amin\", exist_ok=True)\n",
    "out_csv = \"/home/jupyter-amin/mrl_prefix_results_cardiomegaly_gpu_fast.csv\"\n",
    "res_df.to_csv(out_csv, index=False)\n",
    "with open(\"/home/jupyter-amin/mrl_D_star.txt\", \"w\") as f:\n",
    "    f.write(str(D_star))\n",
    "print(\"Saved:\", out_csv)\n",
    "print(\"D* saved to /home/jupyter-amin/mrl_D_star.txt  ->\", D_star)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c34a5cf-3af0-4dd4-b9cd-64699d7ae72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda | D_use: 1536\n",
      "Label columns: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity', 'No Finding', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n",
      "N: 27376 | K labels: 14\n",
      "[Fold 1/3] Macro AUC 0.781 | Macro F1 0.057\n",
      "[Fold 2/3] Macro AUC 0.779 | Macro F1 0.058\n",
      "[Fold 3/3] Macro AUC 0.779 | Macro F1 0.058\n",
      "\n",
      "== Multi-label @ D=1536 | Macro AUC 0.780±0.001 | Macro F1 0.058±0.000\n",
      "Per-label results saved to: /home/jupyter-amin/multilabel_results_D1536.csv\n",
      "\n",
      "Top-5 labels by AUC:\n",
      "               label  auc_mean   auc_std  f1_mean  f1_std\n",
      "9   Pleural Effusion  0.895207  0.004925      0.0     0.0\n",
      "3              Edema  0.860264  0.011173      0.0     0.0\n",
      "13   Support Devices  0.844257  0.007196      0.0     0.0\n",
      "12      Pneumothorax  0.822059  0.022788      0.0     0.0\n",
      "2      Consolidation  0.817530  0.006071      0.0     0.0\n"
     ]
    }
   ],
   "source": [
    "# ==== Multi-label GPU baseline on fused embeddings ====\n",
    "import numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "# --------- 0) Config ----------\n",
    "# Use your Matryoshka operating dimension if you chose one; else use full\n",
    "D_use = min(1536, X_fused.shape[1])   # set to 1536 if that's your D*, or X_fused.shape[1] for full\n",
    "folds = 3                             # 3 for speed; use 5 for final\n",
    "epochs = 8                            # bump for stronger results (e.g., 10–15)\n",
    "lr = 5e-3\n",
    "weight_decay = 1e-4\n",
    "batch_size = 8192                     # increase if GPU RAM allows\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device, \"| D_use:\", D_use)\n",
    "\n",
    "# --------- 1) Select label columns ----------\n",
    "# Heuristic: take numeric columns that look like labels (0/1/-1) and exclude obvious metadata\n",
    "meta_cols = {\"subject_id\",\"study_id\",\"dicom_id\",\"patient_id\",\"view\",\"Rows\",\"Columns\",\"StudyDate\",\"StudyTime\",\n",
    "             \"ProcedureCodeSequence_CodeMeaning\",\"ViewCodeSequence_CodeMeaning\",\n",
    "             \"PatientOrientationCodeSequence_CodeMeaning\",\"offset_day_int\"}\n",
    "# choose numeric columns not in meta\n",
    "candidate_cols = [c for c in ds.csv.columns\n",
    "                  if c not in meta_cols and np.issubdtype(ds.csv[c].dtype, np.number)]\n",
    "# keep columns that contain at least some 0/1 (and possibly -1)\n",
    "def looks_like_label(col):\n",
    "    vals = set(np.unique(ds.csv[col].dropna().astype(int)))\n",
    "    return len(vals & {0,1}) > 0\n",
    "label_cols = [c for c in candidate_cols if looks_like_label(c)]\n",
    "label_cols = sorted(label_cols)  # optional: order\n",
    "print(\"Label columns:\", label_cols)\n",
    "\n",
    "# If you want a fixed set, uncomment and edit:\n",
    "# label_cols = [\"Atelectasis\",\"Cardiomegaly\",\"Consolidation\",\"Edema\",\"Enlarged Cardiomediastinum\",\n",
    "#               \"Fracture\",\"Lung Lesion\",\"Lung Opacity\",\"Pleural Effusion\",\"Pleural Other\",\n",
    "#               \"Pneumonia\",\"Pneumothorax\",\"Support Devices\"]\n",
    "\n",
    "K = len(label_cols)\n",
    "assert K > 0, \"No label columns detected.\"\n",
    "\n",
    "# --------- 2) Build X, Y, and mask (handle -1 as 'unknown') ----------\n",
    "X_all = X_fused[:, :D_use].astype(np.float32)                  # (N, D_use)\n",
    "Y_raw = ds.csv[label_cols].astype(float).to_numpy()            # (N, K), values in {-1,0,1}\n",
    "M_mask = (Y_raw != -1).astype(np.float32)                      # 1 if known, 0 if unknown\n",
    "Y_bin  = np.clip(Y_raw, 0, 1).astype(np.float32)               # map -1->0 just for array shape; will mask\n",
    "\n",
    "N = X_all.shape[0]\n",
    "print(\"N:\", N, \"| K labels:\", K)\n",
    "\n",
    "# --------- 3) Model ----------\n",
    "class MultiLabelHead(nn.Module):\n",
    "    def __init__(self, d_in, k_out):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(d_in, k_out)\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)   # logits (N, K)\n",
    "\n",
    "def masked_bce_with_logits(logits, targets, mask):\n",
    "    # logits/targets/mask: (N, K)\n",
    "    loss_all = nn.functional.binary_cross_entropy_with_logits(logits, targets, reduction=\"none\")\n",
    "    loss_all = loss_all * mask\n",
    "    denom = torch.clamp(mask.sum(), min=1.0)\n",
    "    return loss_all.sum() / denom\n",
    "\n",
    "# --------- 4) CV training/eval ----------\n",
    "def run_fold(train_idx, val_idx):\n",
    "    Xtr = torch.from_numpy(X_all[train_idx]).to(device, non_blocking=True)\n",
    "    Ytr = torch.from_numpy(Y_bin[train_idx]).to(device, non_blocking=True)\n",
    "    Mtr = torch.from_numpy(M_mask[train_idx]).to(device, non_blocking=True)\n",
    "\n",
    "    Xva = torch.from_numpy(X_all[val_idx]).to(device, non_blocking=True)\n",
    "    Yva = torch.from_numpy(Y_bin[val_idx]).to(device, non_blocking=True)\n",
    "    Mva = torch.from_numpy(M_mask[val_idx]).to(device, non_blocking=True)\n",
    "\n",
    "    model = MultiLabelHead(D_use, K).to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # mini-batch indices\n",
    "    nb = int(np.ceil(len(train_idx) / batch_size))\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        perm = torch.randperm(len(train_idx), device=device)\n",
    "        for b in range(nb):\n",
    "            sl = perm[b*batch_size : (b+1)*batch_size]\n",
    "            xb, yb, mb = Xtr[sl], Ytr[sl], Mtr[sl]\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(xb)\n",
    "            loss = masked_bce_with_logits(logits, yb, mb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    # eval: per-label AUC (only where mask==1 in val)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(Xva)\n",
    "        probs = torch.sigmoid(logits).float().cpu().numpy()\n",
    "        ytrue = Yva.float().cpu().numpy()\n",
    "        mmask = Mva.float().cpu().numpy()\n",
    "\n",
    "    # compute per-label AUC, F1 with threshold 0.5; skip labels with no positives/negatives\n",
    "    aucs, f1s = [], []\n",
    "    per_label = []\n",
    "    for j, name in enumerate(label_cols):\n",
    "        m = mmask[:, j] > 0.5\n",
    "        yj = ytrue[m, j].astype(int)\n",
    "        pj = probs[m, j]\n",
    "        if len(yj) == 0 or len(np.unique(yj)) < 2:\n",
    "            auc = np.nan\n",
    "            f1  = np.nan\n",
    "        else:\n",
    "            try:\n",
    "                auc = roc_auc_score(yj, pj)\n",
    "            except Exception:\n",
    "                auc = np.nan\n",
    "            f1 = f1_score(yj, (pj >= 0.5).astype(int)) if (yj.sum() > 0 and (1 - yj).sum() > 0) else np.nan\n",
    "        per_label.append((name, auc, f1, m.sum()))\n",
    "        if not np.isnan(auc): aucs.append(auc)\n",
    "        if not np.isnan(f1):  f1s.append(f1)\n",
    "\n",
    "    macro_auc = float(np.nanmean(aucs)) if len(aucs) else np.nan\n",
    "    macro_f1  = float(np.nanmean(f1s))  if len(f1s)  else np.nan\n",
    "    return macro_auc, macro_f1, per_label\n",
    "\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "per_label_accum = {name: [] for name in label_cols}\n",
    "per_label_f1acc = {name: [] for name in label_cols}\n",
    "\n",
    "for fi, (tr, va) in enumerate(kf.split(np.arange(N))):\n",
    "    macro_auc, macro_f1, per_label = run_fold(tr, va)\n",
    "    print(f\"[Fold {fi+1}/{folds}] Macro AUC {macro_auc:.3f} | Macro F1 {macro_f1:.3f}\")\n",
    "    fold_results.append((macro_auc, macro_f1))\n",
    "    for name, auc, f1, n in per_label:\n",
    "        if not np.isnan(auc): per_label_accum[name].append(auc)\n",
    "        if not np.isnan(f1):  per_label_f1acc[name].append(f1)\n",
    "\n",
    "# --------- 5) Summaries ----------\n",
    "macro_auc_mean = float(np.mean([a for a,_ in fold_results]))\n",
    "macro_auc_std  = float(np.std([a for a,_ in fold_results]))\n",
    "macro_f1_mean  = float(np.mean([f for _,f in fold_results]))\n",
    "macro_f1_std   = float(np.std([f for _,f in fold_results]))\n",
    "print(f\"\\n== Multi-label @ D={D_use} | Macro AUC {macro_auc_mean:.3f}±{macro_auc_std:.3f} | \"\n",
    "      f\"Macro F1 {macro_f1_mean:.3f}±{macro_f1_std:.3f}\")\n",
    "\n",
    "rows = []\n",
    "for name in label_cols:\n",
    "    aucs = per_label_accum[name]\n",
    "    f1s  = per_label_f1acc[name]\n",
    "    rows.append({\n",
    "        \"label\": name,\n",
    "        \"auc_mean\": float(np.mean(aucs)) if len(aucs) else np.nan,\n",
    "        \"auc_std\":  float(np.std(aucs))  if len(aucs) else np.nan,\n",
    "        \"f1_mean\":  float(np.mean(f1s))  if len(f1s) else np.nan,\n",
    "        \"f1_std\":   float(np.std(f1s))   if len(f1s) else np.nan,\n",
    "    })\n",
    "res_df = pd.DataFrame(rows).sort_values(\"auc_mean\", ascending=False)\n",
    "out_csv = \"/home/jupyter-amin/multilabel_results_D{}.csv\".format(D_use)\n",
    "res_df.to_csv(out_csv, index=False)\n",
    "print(\"Per-label results saved to:\", out_csv)\n",
    "\n",
    "# Top-5 labels by AUC\n",
    "print(\"\\nTop-5 labels by AUC:\")\n",
    "print(res_df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "478df3c2-22ce-48db-8ed3-b72c910b5942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Emory dataset...\n",
      "Emory dataset size: 2000\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/home/jupyter-jacob/fsx/embeddings/EmoryCXR/embds_BiomedCLIP/1.2.826.0.1.3680043.8.498.20757941512324792052233950872552042406.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmory dataset size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(emory_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Get a sample to check embedding shape\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m sample = \u001b[43memory_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmory embedding shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample[\u001b[33m'\u001b[39m\u001b[33memb\u001b[39m\u001b[33m'\u001b[39m].shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLabels shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample[\u001b[33m'\u001b[39m\u001b[33mlab\u001b[39m\u001b[33m'\u001b[39m].shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/shared/team2/data/loader.py:292\u001b[39m, in \u001b[36mEmoryDataset.__getitem__\u001b[39m\u001b[34m(self, i)\u001b[39m\n\u001b[32m    290\u001b[39m sample[\u001b[33m\"\u001b[39m\u001b[33mstudy_id\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m.csv.iloc[i][\u001b[33m\"\u001b[39m\u001b[33mAccessionNumber_anon\u001b[39m\u001b[33m\"\u001b[39m]))\n\u001b[32m    291\u001b[39m sample[\u001b[33m\"\u001b[39m\u001b[33mlab\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.labels[i]\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m sample[\u001b[33m\"\u001b[39m\u001b[33memb\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcsv\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSOP\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sample\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/shared/team2/data/loader.py:328\u001b[39m, in \u001b[36mEmoryDataset.load_embedding\u001b[39m\u001b[34m(self, embedding_id)\u001b[39m\n\u001b[32m    326\u001b[39m merged_emb = []\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m embedding_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m.embedding_d.keys()):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     emb = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_dicom_path\u001b[49m\u001b[43m/\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43membds_\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m+\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43membedding_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m/\u001b[49m\u001b[43membedding_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m.npy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m     merged_emb.append(emb)\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.concat(merged_emb)                \n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:454\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    452\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    455\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: '/home/jupyter-jacob/fsx/embeddings/EmoryCXR/embds_BiomedCLIP/1.2.826.0.1.3680043.8.498.20757941512324792052233950872552042406.npy'"
     ]
    }
   ],
   "source": [
    "# Test on Emory dataset\n",
    "from loader import EmoryDataset\n",
    "\n",
    "print(\"Loading Emory dataset...\")\n",
    "emory_dataset = EmoryDataset(\n",
    "    mode=\"test\", \n",
    "    embedding_type=\"All\",\n",
    "    unique_patients=True\n",
    ")\n",
    "\n",
    "print(f\"Emory dataset size: {len(emory_dataset)}\")\n",
    "\n",
    "# Get a sample to check embedding shape\n",
    "sample = emory_dataset[0]\n",
    "print(f\"Emory embedding shape: {sample['emb'].shape}\")\n",
    "print(f\"Labels shape: {sample['lab'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e611bfa-6f73-48f8-97d4-b0bc583e0688",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking access to: /home/jupyter-amin/fsx/embeddings/EmoryCXR\n",
      "✅ embds_BiomedCLIP: 3 files found\n",
      "✅ embds_CheXagent: 3 files found\n",
      "✅ embds_MedGemma: 3 files found\n",
      "✅ embds_RAD-DINO: 3 files found\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if you can access the embedding directories\n",
    "base_path = Path(\"~/fsx/embeddings/EmoryCXR/\").expanduser()\n",
    "print(f\"Checking access to: {base_path}\")\n",
    "\n",
    "embedding_dirs = [\n",
    "    \"embds_BiomedCLIP\",\n",
    "    \"embds_CheXagent\", \n",
    "    \"embds_MedGemma\",\n",
    "    \"embds_RAD-DINO\"\n",
    "]\n",
    "\n",
    "for dir_name in embedding_dirs:\n",
    "    dir_path = base_path / dir_name\n",
    "    if dir_path.exists():\n",
    "        try:\n",
    "            files = list(dir_path.iterdir())[:3]  # First 3 files\n",
    "            print(f\"✅ {dir_name}: {len(files)} files found\")\n",
    "        except PermissionError:\n",
    "            print(f\"❌ {dir_name}: Permission denied\")\n",
    "    else:\n",
    "        print(f\"❌ {dir_name}: Directory not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "13528dd6-2247-4615-866e-8ffedbad8607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Emory dataset with corrected path...\n",
      "Emory dataset size: 2000\n",
      "✅ SUCCESS!\n",
      "Emory fused embedding shape: (3456,)\n",
      "Labels shape: (13,)\n",
      "Same 4-model fusion as MIMIC: (3456,)\n"
     ]
    }
   ],
   "source": [
    "# Fix the EmoryDataset path and test it\n",
    "from loader import EmoryDataset\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Creating Emory dataset with corrected path...\")\n",
    "\n",
    "# Create the dataset\n",
    "emory_dataset = EmoryDataset(\n",
    "    mode=\"test\",\n",
    "    embedding_type=\"All\", \n",
    "    unique_patients=True\n",
    ")\n",
    "\n",
    "print(f\"Emory dataset size: {len(emory_dataset)}\")\n",
    "\n",
    "# Fix the path issue (change from jupyter-jacob to jupyter-amin)\n",
    "emory_dataset.base_dicom_path = Path(\"/home/jupyter-amin/fsx/embeddings/EmoryCXR/\")\n",
    "\n",
    "# Now test loading a sample\n",
    "try:\n",
    "    sample = emory_dataset[0]\n",
    "    print(f\"✅ SUCCESS!\")\n",
    "    print(f\"Emory fused embedding shape: {sample['emb'].shape}\")\n",
    "    print(f\"Labels shape: {sample['lab'].shape}\")\n",
    "    \n",
    "    # Check if it's the same shape as MIMIC\n",
    "    print(f\"Same 4-model fusion as MIMIC: {sample['emb'].shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d8c5d17-0e82-4208-a6ef-2e8c170c0a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all Emory test samples...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable. Did you mean: 'tqdm.tqdm(...)'?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[42]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading all Emory test samples...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m emory_samples = []\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43memory_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m      7\u001b[39m         sample = emory_dataset[i]\n",
      "\u001b[31mTypeError\u001b[39m: 'module' object is not callable. Did you mean: 'tqdm.tqdm(...)'?"
     ]
    }
   ],
   "source": [
    "# Load all Emory test samples for evaluation\n",
    "print(\"Loading all Emory test samples...\")\n",
    "\n",
    "emory_samples = []\n",
    "for i in tqdm(range(len(emory_dataset))):\n",
    "    try:\n",
    "        sample = emory_dataset[i]\n",
    "        emory_samples.append(sample)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading sample {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Loaded {len(emory_samples)} Emory samples\")\n",
    "\n",
    "# Extract embeddings and labels for evaluation\n",
    "emory_embeddings = []\n",
    "emory_labels = []\n",
    "\n",
    "for sample in emory_samples:\n",
    "    emory_embeddings.append(sample['emb'])\n",
    "    emory_labels.append(sample['lab'])\n",
    "\n",
    "emory_embeddings = np.array(emory_embeddings)\n",
    "emory_labels = np.array(emory_labels)\n",
    "\n",
    "print(f\"Emory embeddings final shape: {emory_embeddings.shape}\")\n",
    "print(f\"Emory labels final shape: {emory_labels.shape}\")\n",
    "print(\"Ready for evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "71095f39-c3c0-49ef-80dc-06a7bf6d2411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading all Emory test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:19<00:00, 105.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2000 Emory samples\n",
      "Emory embeddings final shape: (2000, 3456)\n",
      "Emory labels final shape: (2000, 13)\n",
      "Ready for evaluation!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Load all Emory test samples for evaluation\n",
    "print(\"Loading all Emory test samples...\")\n",
    "\n",
    "emory_samples = []\n",
    "for i in tqdm(range(len(emory_dataset))):\n",
    "    try:\n",
    "        sample = emory_dataset[i]\n",
    "        emory_samples.append(sample)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading sample {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"Loaded {len(emory_samples)} Emory samples\")\n",
    "\n",
    "# Extract embeddings and labels for evaluation\n",
    "emory_embeddings = []\n",
    "emory_labels = []\n",
    "\n",
    "for sample in emory_samples:\n",
    "    emory_embeddings.append(sample['emb'])\n",
    "    emory_labels.append(sample['lab'])\n",
    "\n",
    "emory_embeddings = np.array(emory_embeddings)\n",
    "emory_labels = np.array(emory_labels)\n",
    "\n",
    "print(f\"Emory embeddings final shape: {emory_embeddings.shape}\")\n",
    "print(f\"Emory labels final shape: {emory_labels.shape}\")\n",
    "print(\"Ready for evaluation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a72551f-0ba0-4996-84dd-e0c28a92e5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda | D_use: 1536\n",
      "Label columns: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Enlarged Cardiomediastinum', 'Fracture', 'Lung Lesion', 'Lung Opacity', 'Pleural Effusion', 'Pleural Other', 'Pneumonia', 'Pneumothorax', 'Support Devices']\n",
      "N: 2000 | K labels: 13\n"
     ]
    }
   ],
   "source": [
    "# Adapt the evaluation code for Emory data\n",
    "import numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "# --------- 0) Config ----------\n",
    "X_fused = emory_embeddings  # Your Emory embeddings (2000, 3456)\n",
    "D_use = min(1536, X_fused.shape[1])   # Use 1536 or full dimension\n",
    "folds = 3                             \n",
    "epochs = 8                            \n",
    "lr = 5e-3\n",
    "weight_decay = 1e-4\n",
    "batch_size = 512  # Smaller since Emory has only 2000 samples\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device, \"| D_use:\", D_use)\n",
    "\n",
    "# --------- 1) Use the same label columns as MIMIC ----------\n",
    "label_cols = [\"Atelectasis\",\"Cardiomegaly\",\"Consolidation\",\"Edema\",\"Enlarged Cardiomediastinum\",\n",
    "              \"Fracture\",\"Lung Lesion\",\"Lung Opacity\",\"Pleural Effusion\",\"Pleural Other\",\n",
    "              \"Pneumonia\",\"Pneumothorax\",\"Support Devices\"]\n",
    "\n",
    "K = len(label_cols)\n",
    "print(\"Label columns:\", label_cols)\n",
    "print(\"N:\", X_fused.shape[0], \"| K labels:\", K)\n",
    "\n",
    "# --------- 2) Build X, Y for Emory ----------\n",
    "X_all = X_fused[:, :D_use].astype(np.float32)                  # (2000, D_use)\n",
    "Y_bin = emory_labels.astype(np.float32)                        # (2000, 13) - already 0/1\n",
    "M_mask = np.ones_like(Y_bin)                                   # All labels are known (no -1s)\n",
    "\n",
    "N = X_all.shape[0]\n",
    "\n",
    "# Use the same model and training code...\n",
    "# [Rest of the code stays exactly the same]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64fd3f10-5453-4085-8cc2-b93b8efdf093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Emory evaluation...\n",
      "[Fold 1/3] Macro AUC 0.820 | Macro F1 0.122\n",
      "[Fold 2/3] Macro AUC 0.838 | Macro F1 0.113\n",
      "[Fold 3/3] Macro AUC 0.827 | Macro F1 0.120\n",
      "\n",
      "== EMORY Results @ D=1536 | Macro AUC 0.828±0.007 | Macro F1 0.118±0.004\n",
      "\n",
      "== COMPARISON ==\n",
      "MIMIC:  Macro AUC 0.780±0.001 | 27,376 samples | 2688 dims\n",
      "EMORY:  Macro AUC 0.828±0.007 | 2,000 samples | 3456 dims\n"
     ]
    }
   ],
   "source": [
    "# --------- 3) Model ----------\n",
    "class MultiLabelHead(nn.Module):\n",
    "    def __init__(self, d_in, k_out):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(d_in, k_out)\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)   # logits (N, K)\n",
    "\n",
    "def masked_bce_with_logits(logits, targets, mask):\n",
    "    # logits/targets/mask: (N, K)\n",
    "    loss_all = nn.functional.binary_cross_entropy_with_logits(logits, targets, reduction=\"none\")\n",
    "    loss_all = loss_all * mask\n",
    "    denom = torch.clamp(mask.sum(), min=1.0)\n",
    "    return loss_all.sum() / denom\n",
    "\n",
    "# --------- 4) CV training/eval ----------\n",
    "def run_fold(train_idx, val_idx):\n",
    "    Xtr = torch.from_numpy(X_all[train_idx]).to(device, non_blocking=True)\n",
    "    Ytr = torch.from_numpy(Y_bin[train_idx]).to(device, non_blocking=True)\n",
    "    Mtr = torch.from_numpy(M_mask[train_idx]).to(device, non_blocking=True)\n",
    "\n",
    "    Xva = torch.from_numpy(X_all[val_idx]).to(device, non_blocking=True)\n",
    "    Yva = torch.from_numpy(Y_bin[val_idx]).to(device, non_blocking=True)\n",
    "    Mva = torch.from_numpy(M_mask[val_idx]).to(device, non_blocking=True)\n",
    "\n",
    "    model = MultiLabelHead(D_use, K).to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # mini-batch indices\n",
    "    nb = int(np.ceil(len(train_idx) / batch_size))\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        perm = torch.randperm(len(train_idx), device=device)\n",
    "        for b in range(nb):\n",
    "            sl = perm[b*batch_size : (b+1)*batch_size]\n",
    "            xb, yb, mb = Xtr[sl], Ytr[sl], Mtr[sl]\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(xb)\n",
    "            loss = masked_bce_with_logits(logits, yb, mb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    # eval: per-label AUC (only where mask==1 in val)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(Xva)\n",
    "        probs = torch.sigmoid(logits).float().cpu().numpy()\n",
    "        ytrue = Yva.float().cpu().numpy()\n",
    "        mmask = Mva.float().cpu().numpy()\n",
    "\n",
    "    # compute per-label AUC, F1 with threshold 0.5\n",
    "    aucs, f1s = [], []\n",
    "    per_label = []\n",
    "    for j, name in enumerate(label_cols):\n",
    "        m = mmask[:, j] > 0.5\n",
    "        yj = ytrue[m, j].astype(int)\n",
    "        pj = probs[m, j]\n",
    "        if len(yj) == 0 or len(np.unique(yj)) < 2:\n",
    "            auc = np.nan\n",
    "            f1  = np.nan\n",
    "        else:\n",
    "            try:\n",
    "                auc = roc_auc_score(yj, pj)\n",
    "            except Exception:\n",
    "                auc = np.nan\n",
    "            f1 = f1_score(yj, (pj >= 0.5).astype(int)) if (yj.sum() > 0 and (1 - yj).sum() > 0) else np.nan\n",
    "        per_label.append((name, auc, f1, m.sum()))\n",
    "        if not np.isnan(auc): aucs.append(auc)\n",
    "        if not np.isnan(f1):  f1s.append(f1)\n",
    "\n",
    "    macro_auc = float(np.nanmean(aucs)) if len(aucs) else np.nan\n",
    "    macro_f1  = float(np.nanmean(f1s))  if len(f1s)  else np.nan\n",
    "    return macro_auc, macro_f1, per_label\n",
    "\n",
    "# --------- 5) Run cross-validation ----------\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "fold_results = []\n",
    "per_label_accum = {name: [] for name in label_cols}\n",
    "per_label_f1acc = {name: [] for name in label_cols}\n",
    "\n",
    "print(\"Running Emory evaluation...\")\n",
    "for fi, (tr, va) in enumerate(kf.split(np.arange(N))):\n",
    "    macro_auc, macro_f1, per_label = run_fold(tr, va)\n",
    "    print(f\"[Fold {fi+1}/{folds}] Macro AUC {macro_auc:.3f} | Macro F1 {macro_f1:.3f}\")\n",
    "    fold_results.append((macro_auc, macro_f1))\n",
    "    for name, auc, f1, n in per_label:\n",
    "        if not np.isnan(auc): per_label_accum[name].append(auc)\n",
    "        if not np.isnan(f1):  per_label_f1acc[name].append(f1)\n",
    "\n",
    "# --------- 6) Final Results ----------\n",
    "macro_auc_mean = float(np.mean([a for a,_ in fold_results]))\n",
    "macro_auc_std  = float(np.std([a for a,_ in fold_results]))\n",
    "macro_f1_mean  = float(np.mean([f for _,f in fold_results]))\n",
    "macro_f1_std   = float(np.std([f for _,f in fold_results]))\n",
    "\n",
    "print(f\"\\n== EMORY Results @ D={D_use} | Macro AUC {macro_auc_mean:.3f}±{macro_auc_std:.3f} | \"\n",
    "      f\"Macro F1 {macro_f1_mean:.3f}±{macro_f1_std:.3f}\")\n",
    "\n",
    "# Compare with MIMIC results\n",
    "print(f\"\\n== COMPARISON ==\")\n",
    "print(f\"MIMIC:  Macro AUC 0.780±0.001 | 27,376 samples | 2688 dims\")  \n",
    "print(f\"EMORY:  Macro AUC {macro_auc_mean:.3f}±{macro_auc_std:.3f} | 2,000 samples | 3456 dims\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6fb362e-98f7-45ad-836e-865eb30b3c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATRYOSHKA REPRESENTATION LEARNING\n",
      "Multi-Hospital Validation on Fused Medical Embeddings\n",
      "============================================================\n",
      "Starting MRL training on both datasets...\n",
      "This will take a few minutes...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MRLMultiLabelHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Matryoshka Representation Learning Multi-Label Classifier\n",
    "    Can operate at different nesting dimensions\n",
    "    \"\"\"\n",
    "    def __init__(self, max_dim, num_labels, hidden_dims=[512, 256]):\n",
    "        super().__init__()\n",
    "        self.max_dim = max_dim\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        # Build classifier that can handle variable input sizes\n",
    "        layers = []\n",
    "        prev_dim = max_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Final layer\n",
    "        layers.append(nn.Linear(prev_dim, num_labels))\n",
    "        self.classifier = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x, truncate_dim=None):\n",
    "        \"\"\"\n",
    "        Forward pass with optional dimension truncation\n",
    "        Args:\n",
    "            x: input tensor [batch_size, full_dim] \n",
    "            truncate_dim: if specified, use only first truncate_dim features\n",
    "        \"\"\"\n",
    "        if truncate_dim is not None and truncate_dim < x.shape[1]:\n",
    "            x = x[:, :truncate_dim]\n",
    "        return self.classifier(x)\n",
    "\n",
    "def mrl_loss(model, x, y, mask, nesting_levels, level_weights=None, device='cuda'):\n",
    "    \"\"\"\n",
    "    Compute MRL loss across multiple nesting levels\n",
    "    \n",
    "    Args:\n",
    "        model: MRLMultiLabelHead model\n",
    "        x, y, mask: input data, labels, mask tensors\n",
    "        nesting_levels: list of dimensions to train [64, 128, 256, ...]\n",
    "        level_weights: weights for each nesting level\n",
    "        device: cuda or cpu\n",
    "    \"\"\"\n",
    "    if level_weights is None:\n",
    "        level_weights = {level: 1.0 for level in nesting_levels}\n",
    "    \n",
    "    total_loss = 0\n",
    "    level_losses = {}\n",
    "    \n",
    "    for level in nesting_levels:\n",
    "        # Get predictions at this nesting level\n",
    "        logits = model(x, truncate_dim=level)\n",
    "        \n",
    "        # Masked binary cross entropy\n",
    "        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, y, reduction='none'\n",
    "        )\n",
    "        masked_loss = (bce_loss * mask).sum() / torch.clamp(mask.sum(), min=1.0)\n",
    "        \n",
    "        # Weight and accumulate\n",
    "        weighted_loss = level_weights[level] * masked_loss\n",
    "        total_loss += weighted_loss\n",
    "        level_losses[level] = masked_loss.item()\n",
    "    \n",
    "    return total_loss, level_losses\n",
    "\n",
    "def evaluate_mrl_model(model, x, y, mask, nesting_levels, label_names, device='cuda'):\n",
    "    \"\"\"\n",
    "    Evaluate MRL model at all nesting levels\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    results = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for level in nesting_levels:\n",
    "            # Get predictions at this level\n",
    "            logits = model(x, truncate_dim=level)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            y_true = y.cpu().numpy()\n",
    "            m = mask.cpu().numpy()\n",
    "            \n",
    "            # Compute metrics\n",
    "            aucs = []\n",
    "            f1s = []\n",
    "            \n",
    "            for j, name in enumerate(label_names):\n",
    "                mask_j = m[:, j] > 0.5\n",
    "                if mask_j.sum() == 0:\n",
    "                    continue\n",
    "                    \n",
    "                yj = y_true[mask_j, j].astype(int)\n",
    "                pj = probs[mask_j, j]\n",
    "                \n",
    "                if len(np.unique(yj)) < 2:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    auc = roc_auc_score(yj, pj)\n",
    "                    aucs.append(auc)\n",
    "                    \n",
    "                    pred_j = (pj >= 0.5).astype(int)\n",
    "                    if yj.sum() > 0 and (1 - yj).sum() > 0:\n",
    "                        f1 = f1_score(yj, pred_j)\n",
    "                        f1s.append(f1)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            # Store results for this level\n",
    "            results[level] = {\n",
    "                'macro_auc': np.mean(aucs) if aucs else 0.0,\n",
    "                'macro_f1': np.mean(f1s) if f1s else 0.0,\n",
    "                'valid_labels': len(aucs)\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def train_mrl_on_dataset(X_data, Y_data, dataset_name, nesting_levels=[64, 128, 256, 512, 1024, 1536]):\n",
    "    \"\"\"\n",
    "    Train MRL model on a dataset (MIMIC or Emory)\n",
    "    \n",
    "    Args:\n",
    "        X_data: embeddings array\n",
    "        Y_data: labels array  \n",
    "        dataset_name: \"MIMIC\" or \"EMORY\"\n",
    "        nesting_levels: list of nesting dimensions\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING MRL ON {dataset_name} DATASET\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    max_dim = min(max(nesting_levels), X_data.shape[1])\n",
    "    epochs = 12\n",
    "    lr = 3e-3\n",
    "    weight_decay = 1e-4\n",
    "    batch_size = 512 if dataset_name == \"EMORY\" else 2048\n",
    "    folds = 3\n",
    "    \n",
    "    # Adjust nesting levels to data dimensions\n",
    "    valid_levels = [level for level in nesting_levels if level <= X_data.shape[1]]\n",
    "    if X_data.shape[1] not in valid_levels:\n",
    "        valid_levels.append(X_data.shape[1])\n",
    "    valid_levels = sorted(valid_levels)\n",
    "    \n",
    "    print(f\"Dataset: {X_data.shape[0]} samples, {X_data.shape[1]} dimensions\")\n",
    "    print(f\"MRL nesting levels: {valid_levels}\")\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X_all = X_data[:, :max_dim].astype(np.float32)\n",
    "    Y_all = Y_data.astype(np.float32)\n",
    "    M_all = np.ones_like(Y_all)  # No missing labels\n",
    "    \n",
    "    # Label names\n",
    "    label_names = [\"Atelectasis\",\"Cardiomegaly\",\"Consolidation\",\"Edema\",\"Enlarged Cardiomediastinum\",\n",
    "                   \"Fracture\",\"Lung Lesion\",\"Lung Opacity\",\"Pleural Effusion\",\"Pleural Other\",\n",
    "                   \"Pneumonia\",\"Pneumothorax\",\"Support Devices\"]\n",
    "    \n",
    "    # Level weights (higher weight for smaller levels)\n",
    "    level_weights = {}\n",
    "    for level in valid_levels:\n",
    "        if level <= 256:\n",
    "            level_weights[level] = 2.0\n",
    "        elif level <= 1024:\n",
    "            level_weights[level] = 1.5\n",
    "        else:\n",
    "            level_weights[level] = 1.0\n",
    "    \n",
    "    print(f\"Level weights: {level_weights}\")\n",
    "    \n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    fold_results = {level: [] for level in valid_levels}\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_all)):\n",
    "        print(f\"\\n--- Fold {fold_idx + 1}/{folds} ---\")\n",
    "        \n",
    "        # Prepare fold data\n",
    "        X_train = torch.from_numpy(X_all[train_idx]).to(device)\n",
    "        Y_train = torch.from_numpy(Y_all[train_idx]).to(device)\n",
    "        M_train = torch.from_numpy(M_all[train_idx]).to(device)\n",
    "        \n",
    "        X_val = torch.from_numpy(X_all[val_idx]).to(device)\n",
    "        Y_val = torch.from_numpy(Y_all[val_idx]).to(device) \n",
    "        M_val = torch.from_numpy(M_all[val_idx]).to(device)\n",
    "        \n",
    "        # Create model\n",
    "        model = MRLMultiLabelHead(max_dim, len(label_names)).to(device)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        \n",
    "        # Training loop\n",
    "        model.train()\n",
    "        n_batches = int(np.ceil(len(train_idx) / batch_size))\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            perm = torch.randperm(len(train_idx), device=device)\n",
    "            \n",
    "            for batch in range(n_batches):\n",
    "                batch_idx = perm[batch * batch_size:(batch + 1) * batch_size]\n",
    "                x_batch = X_train[batch_idx]\n",
    "                y_batch = Y_train[batch_idx]\n",
    "                m_batch = M_train[batch_idx]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # MRL loss across all nesting levels\n",
    "                loss, level_losses = mrl_loss(\n",
    "                    model, x_batch, y_batch, m_batch, \n",
    "                    valid_levels, level_weights, device\n",
    "                )\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            if (epoch + 1) % 4 == 0:\n",
    "                avg_loss = total_loss / n_batches\n",
    "                print(f\"  Epoch {epoch+1}/{epochs}: Loss = {avg_loss:.4f}\")\n",
    "        \n",
    "        # Evaluate at all nesting levels\n",
    "        val_results = evaluate_mrl_model(\n",
    "            model, X_val, Y_val, M_val, valid_levels, label_names, device\n",
    "        )\n",
    "        \n",
    "        print(\"  Validation Results:\")\n",
    "        for level in valid_levels:\n",
    "            result = val_results[level]\n",
    "            print(f\"    Level {level:4d}: AUC={result['macro_auc']:.4f}, F1={result['macro_f1']:.4f}\")\n",
    "            fold_results[level].append(result['macro_auc'])\n",
    "    \n",
    "    # Final results across all folds\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"FINAL {dataset_name} MRL RESULTS\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    final_results = {}\n",
    "    for level in valid_levels:\n",
    "        aucs = fold_results[level]\n",
    "        mean_auc = np.mean(aucs)\n",
    "        std_auc = np.std(aucs)\n",
    "        final_results[level] = (mean_auc, std_auc)\n",
    "        print(f\"Level {level:4d}: AUC = {mean_auc:.4f} ± {std_auc:.4f}\")\n",
    "    \n",
    "    return final_results\n",
    "\n",
    "def compare_datasets_mrl(mimic_results, emory_results):\n",
    "    \"\"\"\n",
    "    Compare MRL results between MIMIC and Emory\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"MRL COMPARISON: MIMIC vs EMORY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"{'Level':<8} {'MIMIC AUC':<12} {'Emory AUC':<12} {'Difference':<12}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Find common levels\n",
    "    common_levels = sorted(set(mimic_results.keys()) & set(emory_results.keys()))\n",
    "    \n",
    "    for level in common_levels:\n",
    "        mimic_auc, mimic_std = mimic_results[level]\n",
    "        emory_auc, emory_std = emory_results[level]\n",
    "        diff = emory_auc - mimic_auc\n",
    "        \n",
    "        print(f\"{level:<8} {mimic_auc:.4f}±{mimic_std:.3f}  {emory_auc:.4f}±{emory_std:.3f}  {diff:+.4f}\")\n",
    "    \n",
    "    print(f\"\\n🎯 KEY INSIGHTS:\")\n",
    "    print(f\"✅ Your 4-model fusion approach works across different hospitals\")\n",
    "    print(f\"✅ MRL provides multiple speed/accuracy tradeoffs\")\n",
    "    print(f\"✅ Can adapt to different computational budgets\")\n",
    "    \n",
    "    # Performance analysis\n",
    "    best_mimic_level = max(mimic_results.keys(), key=lambda x: mimic_results[x][0])\n",
    "    best_emory_level = max(emory_results.keys(), key=lambda x: emory_results[x][0])\n",
    "    \n",
    "    print(f\"\\n📊 PERFORMANCE SUMMARY:\")\n",
    "    print(f\"MIMIC best: Level {best_mimic_level} with AUC {mimic_results[best_mimic_level][0]:.4f}\")\n",
    "    print(f\"Emory best: Level {best_emory_level} with AUC {emory_results[best_emory_level][0]:.4f}\")\n",
    "    \n",
    "    # Speed vs accuracy tradeoff\n",
    "    if 64 in common_levels and max(common_levels) in common_levels:\n",
    "        fast_level = 64\n",
    "        full_level = max(common_levels)\n",
    "        \n",
    "        mimic_speedup = f\"{mimic_results[fast_level][0]:.3f} → {mimic_results[full_level][0]:.3f}\"\n",
    "        emory_speedup = f\"{emory_results[fast_level][0]:.3f} → {emory_results[full_level][0]:.3f}\"\n",
    "        \n",
    "        print(f\"\\n⚡ SPEED vs ACCURACY:\")\n",
    "        print(f\"MIMIC: {fast_level} dims {mimic_speedup} (fast → full)\")\n",
    "        print(f\"Emory: {fast_level} dims {emory_speedup} (fast → full)\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"MATRYOSHKA REPRESENTATION LEARNING\")\n",
    "    print(\"Multi-Hospital Validation on Fused Medical Embeddings\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # You need to have these variables available from previous cells:\n",
    "    # mimic_embeddings, mimic_labels (from your MIMIC dataset)\n",
    "    # emory_embeddings, emory_labels (from your Emory dataset)\n",
    "    \n",
    "    # Define nesting levels for MRL\n",
    "    nesting_levels = [64, 128, 256, 512, 1024, 1536]\n",
    "    \n",
    "    print(\"Starting MRL training on both datasets...\")\n",
    "    print(\"This will take a few minutes...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5c30751b-4b9e-4075-9e13-9474c6f455b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data availability...\n",
      "Emory data: (2000, 3456) embeddings, (2000, 13) labels\n",
      "Loading MIMIC data for MRL comparison...\n",
      "Loading 9125 MIMIC samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9125/9125 [01:10<00:00, 128.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIMIC data: (9125, 3456) embeddings, (9125, 13) labels\n"
     ]
    }
   ],
   "source": [
    "# Make sure we have the data from previous steps\n",
    "print(\"Checking data availability...\")\n",
    "print(f\"Emory data: {emory_embeddings.shape} embeddings, {emory_labels.shape} labels\")\n",
    "\n",
    "# We need MIMIC data too - let's load it\n",
    "print(\"Loading MIMIC data for MRL comparison...\")\n",
    "\n",
    "# Load MIMIC dataset \n",
    "from loader import MimicDataset\n",
    "\n",
    "mimic_dataset = MimicDataset(mode=\"test\", embedding_type=\"All\", unique_patients=True)\n",
    "mimic_dataset.base_dicom_path = Path(\"/home/jupyter-amin/fsx/embeddings/MIMIC/\")\n",
    "\n",
    "print(f\"Loading {len(mimic_dataset)} MIMIC samples...\")\n",
    "mimic_samples = []\n",
    "for i in tqdm(range(len(mimic_dataset))):\n",
    "    try:\n",
    "        sample = mimic_dataset[i]\n",
    "        mimic_samples.append(sample)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "# Extract MIMIC embeddings and labels\n",
    "mimic_embeddings = np.array([s['emb'] for s in mimic_samples])\n",
    "mimic_labels = np.array([s['lab'] for s in mimic_samples])\n",
    "\n",
    "print(f\"MIMIC data: {mimic_embeddings.shape} embeddings, {mimic_labels.shape} labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c534d22d-0520-4b92-a178-38df97c503d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MIMIC data...\n",
      "Loading 9125 MIMIC samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9125/9125 [01:12<00:00, 126.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIMIC loaded: (9125, 3456) embeddings, (9125, 13) labels\n",
      "Emory ready: (2000, 3456) embeddings, (2000, 13) labels\n",
      "\n",
      "============================================================\n",
      "STARTING MRL TRAINING\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "TRAINING MRL ON MIMIC DATASET\n",
      "============================================================\n",
      "Dataset: 9125 samples, 3456 dimensions\n",
      "MRL nesting levels: [64, 128, 256, 512, 1024, 1536, 3456]\n",
      "Device: cuda\n",
      "Level weights: {64: 2.0, 128: 2.0, 256: 2.0, 512: 1.5, 1024: 1.5, 1536: 1.0, 3456: 1.0}\n",
      "\n",
      "--- Fold 1/3 ---\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2048x64 and 1536x512)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Train MRL on MIMIC\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m mimic_results = \u001b[43mtrain_mrl_on_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmimic_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmimic_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMIMIC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnesting_levels\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1536\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Train MRL on Emory  \u001b[39;00m\n\u001b[32m     40\u001b[39m emory_results = train_mrl_on_dataset(\n\u001b[32m     41\u001b[39m     emory_embeddings, emory_labels, \u001b[33m\"\u001b[39m\u001b[33mEMORY\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     42\u001b[39m     nesting_levels=[\u001b[32m64\u001b[39m, \u001b[32m128\u001b[39m, \u001b[32m256\u001b[39m, \u001b[32m512\u001b[39m, \u001b[32m1024\u001b[39m, \u001b[32m1536\u001b[39m]\n\u001b[32m     43\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 223\u001b[39m, in \u001b[36mtrain_mrl_on_dataset\u001b[39m\u001b[34m(X_data, Y_data, dataset_name, nesting_levels)\u001b[39m\n\u001b[32m    220\u001b[39m optimizer.zero_grad()\n\u001b[32m    222\u001b[39m \u001b[38;5;66;03m# MRL loss across all nesting levels\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m loss, level_losses = \u001b[43mmrl_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_levels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m loss.backward()\n\u001b[32m    229\u001b[39m optimizer.step()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mmrl_loss\u001b[39m\u001b[34m(model, x, y, mask, nesting_levels, level_weights, device)\u001b[39m\n\u001b[32m     62\u001b[39m level_losses = {}\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m level \u001b[38;5;129;01min\u001b[39;00m nesting_levels:\n\u001b[32m     65\u001b[39m     \u001b[38;5;66;03m# Get predictions at this nesting level\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# Masked binary cross entropy\u001b[39;00m\n\u001b[32m     69\u001b[39m     bce_loss = nn.functional.binary_cross_entropy_with_logits(\n\u001b[32m     70\u001b[39m         logits, y, reduction=\u001b[33m'\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     71\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mMRLMultiLabelHead.forward\u001b[39m\u001b[34m(self, x, truncate_dim)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m truncate_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m truncate_dim < x.shape[\u001b[32m1\u001b[39m]:\n\u001b[32m     44\u001b[39m     x = x[:, :truncate_dim]\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/efs/envs/pytorch-env/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mat1 and mat2 shapes cannot be multiplied (2048x64 and 1536x512)"
     ]
    }
   ],
   "source": [
    "# Load MIMIC data for MRL comparison\n",
    "print(\"Loading MIMIC data...\")\n",
    "from pathlib import Path\n",
    "\n",
    "# Load MIMIC dataset \n",
    "mimic_dataset = MimicDataset(mode=\"test\", embedding_type=\"All\", unique_patients=True)\n",
    "# Fix path for your system\n",
    "mimic_dataset.base_dicom_path = Path(\"/home/jupyter-amin/fsx/embeddings/MIMIC/\")\n",
    "\n",
    "print(f\"Loading {len(mimic_dataset)} MIMIC samples...\")\n",
    "mimic_samples = []\n",
    "for i in tqdm(range(len(mimic_dataset))):\n",
    "    try:\n",
    "        sample = mimic_dataset[i]\n",
    "        mimic_samples.append(sample)\n",
    "    except Exception as e:\n",
    "        if i < 5:  # Only print first few errors\n",
    "            print(f\"Error loading sample {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Extract MIMIC embeddings and labels\n",
    "mimic_embeddings = np.array([s['emb'] for s in mimic_samples])\n",
    "mimic_labels = np.array([s['lab'] for s in mimic_samples])\n",
    "\n",
    "print(f\"MIMIC loaded: {mimic_embeddings.shape} embeddings, {mimic_labels.shape} labels\")\n",
    "print(f\"Emory ready: {emory_embeddings.shape} embeddings, {emory_labels.shape} labels\")\n",
    "\n",
    "# Now run MRL training on both datasets\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING MRL TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train MRL on MIMIC\n",
    "mimic_results = train_mrl_on_dataset(\n",
    "    mimic_embeddings, mimic_labels, \"MIMIC\", \n",
    "    nesting_levels=[64, 128, 256, 512, 1024, 1536]\n",
    ")\n",
    "\n",
    "# Train MRL on Emory  \n",
    "emory_results = train_mrl_on_dataset(\n",
    "    emory_embeddings, emory_labels, \"EMORY\",\n",
    "    nesting_levels=[64, 128, 256, 512, 1024, 1536]\n",
    ")\n",
    "\n",
    "# Compare results\n",
    "compare_datasets_mrl(mimic_results, emory_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e38b020c-b033-4b8f-a5da-0b6416a6b6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATRYOSHKA REPRESENTATION LEARNING\n",
      "Multi-Hospital Validation on Fused Medical Embeddings\n",
      "============================================================\n",
      "Starting MRL training on both datasets...\n",
      "This will take a few minutes...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MRLMultiLabelHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Matryoshka Representation Learning Multi-Label Classifier\n",
    "    Creates separate heads for different nesting dimensions\n",
    "    \"\"\"\n",
    "    def __init__(self, max_dim, num_labels, nesting_levels, hidden_dims=[512, 256]):\n",
    "        super().__init__()\n",
    "        self.max_dim = max_dim\n",
    "        self.num_labels = num_labels\n",
    "        self.nesting_levels = nesting_levels\n",
    "        \n",
    "        # Create separate classifier heads for each nesting level\n",
    "        self.classifiers = nn.ModuleDict()\n",
    "        \n",
    "        for level in nesting_levels:\n",
    "            if level > max_dim:\n",
    "                continue\n",
    "                \n",
    "            layers = []\n",
    "            prev_dim = level  # Input size for this level\n",
    "            \n",
    "            # Scale hidden dimensions based on input size\n",
    "            scaled_hidden = [min(h, level * 2) for h in hidden_dims]\n",
    "            \n",
    "            for hidden_dim in scaled_hidden:\n",
    "                layers.extend([\n",
    "                    nn.Linear(prev_dim, hidden_dim),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(0.3)\n",
    "                ])\n",
    "                prev_dim = hidden_dim\n",
    "            \n",
    "            # Final layer\n",
    "            layers.append(nn.Linear(prev_dim, num_labels))\n",
    "            \n",
    "            self.classifiers[str(level)] = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x, truncate_dim=None):\n",
    "        \"\"\"\n",
    "        Forward pass with specific truncation dimension\n",
    "        Args:\n",
    "            x: input tensor [batch_size, full_dim] \n",
    "            truncate_dim: dimension level to use\n",
    "        \"\"\"\n",
    "        if truncate_dim is None:\n",
    "            truncate_dim = max(self.nesting_levels)\n",
    "            \n",
    "        # Truncate input to specified dimension\n",
    "        x_truncated = x[:, :truncate_dim]\n",
    "        \n",
    "        # Use the appropriate classifier head\n",
    "        classifier = self.classifiers[str(truncate_dim)]\n",
    "        return classifier(x_truncated)\n",
    "\n",
    "def mrl_loss(model, x, y, mask, nesting_levels, level_weights=None, device='cuda'):\n",
    "    \"\"\"\n",
    "    Compute MRL loss across multiple nesting levels\n",
    "    \n",
    "    Args:\n",
    "        model: MRLMultiLabelHead model\n",
    "        x, y, mask: input data, labels, mask tensors\n",
    "        nesting_levels: list of dimensions to train [64, 128, 256, ...]\n",
    "        level_weights: weights for each nesting level\n",
    "        device: cuda or cpu\n",
    "    \"\"\"\n",
    "    if level_weights is None:\n",
    "        level_weights = {level: 1.0 for level in nesting_levels}\n",
    "    \n",
    "    total_loss = 0\n",
    "    level_losses = {}\n",
    "    \n",
    "    for level in nesting_levels:\n",
    "        # Get predictions at this nesting level\n",
    "        logits = model(x, truncate_dim=level)\n",
    "        \n",
    "        # Masked binary cross entropy\n",
    "        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n",
    "            logits, y, reduction='none'\n",
    "        )\n",
    "        masked_loss = (bce_loss * mask).sum() / torch.clamp(mask.sum(), min=1.0)\n",
    "        \n",
    "        # Weight and accumulate\n",
    "        weighted_loss = level_weights[level] * masked_loss\n",
    "        total_loss += weighted_loss\n",
    "        level_losses[level] = masked_loss.item()\n",
    "    \n",
    "    return total_loss, level_losses\n",
    "\n",
    "def evaluate_mrl_model(model, x, y, mask, nesting_levels, label_names, device='cuda'):\n",
    "    \"\"\"\n",
    "    Evaluate MRL model at all nesting levels\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    results = {}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for level in nesting_levels:\n",
    "            # Get predictions at this level\n",
    "            logits = model(x, truncate_dim=level)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy()\n",
    "            y_true = y.cpu().numpy()\n",
    "            m = mask.cpu().numpy()\n",
    "            \n",
    "            # Compute metrics\n",
    "            aucs = []\n",
    "            f1s = []\n",
    "            \n",
    "            for j, name in enumerate(label_names):\n",
    "                mask_j = m[:, j] > 0.5\n",
    "                if mask_j.sum() == 0:\n",
    "                    continue\n",
    "                    \n",
    "                yj = y_true[mask_j, j].astype(int)\n",
    "                pj = probs[mask_j, j]\n",
    "                \n",
    "                if len(np.unique(yj)) < 2:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    auc = roc_auc_score(yj, pj)\n",
    "                    aucs.append(auc)\n",
    "                    \n",
    "                    pred_j = (pj >= 0.5).astype(int)\n",
    "                    if yj.sum() > 0 and (1 - yj).sum() > 0:\n",
    "                        f1 = f1_score(yj, pred_j)\n",
    "                        f1s.append(f1)\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            # Store results for this level\n",
    "            results[level] = {\n",
    "                'macro_auc': np.mean(aucs) if aucs else 0.0,\n",
    "                'macro_f1': np.mean(f1s) if f1s else 0.0,\n",
    "                'valid_labels': len(aucs)\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def train_mrl_on_dataset(X_data, Y_data, dataset_name, nesting_levels=[64, 128, 256, 512, 1024, 1536]):\n",
    "    \"\"\"\n",
    "    Train MRL model on a dataset (MIMIC or Emory)\n",
    "    \n",
    "    Args:\n",
    "        X_data: embeddings array\n",
    "        Y_data: labels array  \n",
    "        dataset_name: \"MIMIC\" or \"EMORY\"\n",
    "        nesting_levels: list of nesting dimensions\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"TRAINING MRL ON {dataset_name} DATASET\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    max_dim = min(max(nesting_levels), X_data.shape[1])\n",
    "    epochs = 12\n",
    "    lr = 3e-3\n",
    "    weight_decay = 1e-4\n",
    "    batch_size = 512 if dataset_name == \"EMORY\" else 2048\n",
    "    folds = 3\n",
    "    \n",
    "    # Adjust nesting levels to data dimensions\n",
    "    valid_levels = [level for level in nesting_levels if level <= X_data.shape[1]]\n",
    "    if X_data.shape[1] not in valid_levels:\n",
    "        valid_levels.append(X_data.shape[1])\n",
    "    valid_levels = sorted(valid_levels)\n",
    "    \n",
    "    print(f\"Dataset: {X_data.shape[0]} samples, {X_data.shape[1]} dimensions\")\n",
    "    print(f\"MRL nesting levels: {valid_levels}\")\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    # Prepare data\n",
    "    X_all = X_data[:, :max_dim].astype(np.float32)\n",
    "    Y_all = Y_data.astype(np.float32)\n",
    "    M_all = np.ones_like(Y_all)  # No missing labels\n",
    "    \n",
    "    # Label names\n",
    "    label_names = [\"Atelectasis\",\"Cardiomegaly\",\"Consolidation\",\"Edema\",\"Enlarged Cardiomediastinum\",\n",
    "                   \"Fracture\",\"Lung Lesion\",\"Lung Opacity\",\"Pleural Effusion\",\"Pleural Other\",\n",
    "                   \"Pneumonia\",\"Pneumothorax\",\"Support Devices\"]\n",
    "    \n",
    "    # Level weights (higher weight for smaller levels)\n",
    "    level_weights = {}\n",
    "    for level in valid_levels:\n",
    "        if level <= 256:\n",
    "            level_weights[level] = 2.0\n",
    "        elif level <= 1024:\n",
    "            level_weights[level] = 1.5\n",
    "        else:\n",
    "            level_weights[level] = 1.0\n",
    "    \n",
    "    print(f\"Level weights: {level_weights}\")\n",
    "    \n",
    "    # Cross-validation\n",
    "    kf = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    fold_results = {level: [] for level in valid_levels}\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_all)):\n",
    "        print(f\"\\n--- Fold {fold_idx + 1}/{folds} ---\")\n",
    "        \n",
    "        # Prepare fold data\n",
    "        X_train = torch.from_numpy(X_all[train_idx]).to(device)\n",
    "        Y_train = torch.from_numpy(Y_all[train_idx]).to(device)\n",
    "        M_train = torch.from_numpy(M_all[train_idx]).to(device)\n",
    "        \n",
    "        X_val = torch.from_numpy(X_all[val_idx]).to(device)\n",
    "        Y_val = torch.from_numpy(Y_all[val_idx]).to(device) \n",
    "        M_val = torch.from_numpy(M_all[val_idx]).to(device)\n",
    "        \n",
    "        # Create model\n",
    "        model = MRLMultiLabelHead(max_dim, len(label_names), valid_levels).to(device)\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        \n",
    "        # Training loop\n",
    "        model.train()\n",
    "        n_batches = int(np.ceil(len(train_idx) / batch_size))\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            perm = torch.randperm(len(train_idx), device=device)\n",
    "            \n",
    "            for batch in range(n_batches):\n",
    "                batch_idx = perm[batch * batch_size:(batch + 1) * batch_size]\n",
    "                x_batch = X_train[batch_idx]\n",
    "                y_batch = Y_train[batch_idx]\n",
    "                m_batch = M_train[batch_idx]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # MRL loss across all nesting levels\n",
    "                loss, level_losses = mrl_loss(\n",
    "                    model, x_batch, y_batch, m_batch, \n",
    "                    valid_levels, level_weights, device\n",
    "                )\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            \n",
    "            if (epoch + 1) % 4 == 0:\n",
    "                avg_loss = total_loss / n_batches\n",
    "                print(f\"  Epoch {epoch+1}/{epochs}: Loss = {avg_loss:.4f}\")\n",
    "        \n",
    "        # Evaluate at all nesting levels\n",
    "        val_results = evaluate_mrl_model(\n",
    "            model, X_val, Y_val, M_val, valid_levels, label_names, device\n",
    "        )\n",
    "        \n",
    "        print(\"  Validation Results:\")\n",
    "        for level in valid_levels:\n",
    "            result = val_results[level]\n",
    "            print(f\"    Level {level:4d}: AUC={result['macro_auc']:.4f}, F1={result['macro_f1']:.4f}\")\n",
    "            fold_results[level].append(result['macro_auc'])\n",
    "    \n",
    "    # Final results across all folds\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"FINAL {dataset_name} MRL RESULTS\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    final_results = {}\n",
    "    for level in valid_levels:\n",
    "        aucs = fold_results[level]\n",
    "        mean_auc = np.mean(aucs)\n",
    "        std_auc = np.std(aucs)\n",
    "        final_results[level] = (mean_auc, std_auc)\n",
    "        print(f\"Level {level:4d}: AUC = {mean_auc:.4f} ± {std_auc:.4f}\")\n",
    "    \n",
    "    return final_results\n",
    "\n",
    "def compare_datasets_mrl(mimic_results, emory_results):\n",
    "    \"\"\"\n",
    "    Compare MRL results between MIMIC and Emory\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"MRL COMPARISON: MIMIC vs EMORY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"{'Level':<8} {'MIMIC AUC':<12} {'Emory AUC':<12} {'Difference':<12}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Find common levels\n",
    "    common_levels = sorted(set(mimic_results.keys()) & set(emory_results.keys()))\n",
    "    \n",
    "    for level in common_levels:\n",
    "        mimic_auc, mimic_std = mimic_results[level]\n",
    "        emory_auc, emory_std = emory_results[level]\n",
    "        diff = emory_auc - mimic_auc\n",
    "        \n",
    "        print(f\"{level:<8} {mimic_auc:.4f}±{mimic_std:.3f}  {emory_auc:.4f}±{emory_std:.3f}  {diff:+.4f}\")\n",
    "    \n",
    "    print(f\"\\n🎯 KEY INSIGHTS:\")\n",
    "    print(f\"✅ Your 4-model fusion approach works across different hospitals\")\n",
    "    print(f\"✅ MRL provides multiple speed/accuracy tradeoffs\")\n",
    "    print(f\"✅ Can adapt to different computational budgets\")\n",
    "    \n",
    "    # Performance analysis\n",
    "    best_mimic_level = max(mimic_results.keys(), key=lambda x: mimic_results[x][0])\n",
    "    best_emory_level = max(emory_results.keys(), key=lambda x: emory_results[x][0])\n",
    "    \n",
    "    print(f\"\\n📊 PERFORMANCE SUMMARY:\")\n",
    "    print(f\"MIMIC best: Level {best_mimic_level} with AUC {mimic_results[best_mimic_level][0]:.4f}\")\n",
    "    print(f\"Emory best: Level {best_emory_level} with AUC {emory_results[best_emory_level][0]:.4f}\")\n",
    "    \n",
    "    # Speed vs accuracy tradeoff\n",
    "    if 64 in common_levels and max(common_levels) in common_levels:\n",
    "        fast_level = 64\n",
    "        full_level = max(common_levels)\n",
    "        \n",
    "        mimic_speedup = f\"{mimic_results[fast_level][0]:.3f} → {mimic_results[full_level][0]:.3f}\"\n",
    "        emory_speedup = f\"{emory_results[fast_level][0]:.3f} → {emory_results[full_level][0]:.3f}\"\n",
    "        \n",
    "        print(f\"\\n⚡ SPEED vs ACCURACY:\")\n",
    "        print(f\"MIMIC: {fast_level} dims {mimic_speedup} (fast → full)\")\n",
    "        print(f\"Emory: {fast_level} dims {emory_speedup} (fast → full)\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"MATRYOSHKA REPRESENTATION LEARNING\")\n",
    "    print(\"Multi-Hospital Validation on Fused Medical Embeddings\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # You need to have these variables available from previous cells:\n",
    "    # mimic_embeddings, mimic_labels (from your MIMIC dataset)\n",
    "    # emory_embeddings, emory_labels (from your Emory dataset)\n",
    "    \n",
    "    # Define nesting levels for MRL\n",
    "    nesting_levels = [64, 128, 256, 512, 1024, 1536]\n",
    "    \n",
    "    print(\"Starting MRL training on both datasets...\")\n",
    "    print(\"This will take a few minutes...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c61137a2-2cea-4157-a8e8-c647e0708c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MRL with fixed nesting levels...\n",
      "Truncated MIMIC: (9125, 1536)\n",
      "Truncated Emory: (2000, 1536)\n",
      "\n",
      "============================================================\n",
      "TRAINING MRL ON MIMIC DATASET\n",
      "============================================================\n",
      "Dataset: 9125 samples, 1536 dimensions\n",
      "MRL nesting levels: [128, 256, 512, 1024, 1536]\n",
      "Device: cuda\n",
      "Level weights: {128: 2.0, 256: 2.0, 512: 1.5, 1024: 1.5, 1536: 1.0}\n",
      "\n",
      "--- Fold 1/3 ---\n",
      "  Epoch 4/12: Loss = 1.3761\n",
      "  Epoch 8/12: Loss = 1.2049\n",
      "  Epoch 12/12: Loss = 1.1521\n",
      "  Validation Results:\n",
      "    Level  128: AUC=0.7814, F1=0.0309\n",
      "    Level  256: AUC=0.7892, F1=0.0402\n",
      "    Level  512: AUC=0.7799, F1=0.0320\n",
      "    Level 1024: AUC=0.8302, F1=0.0540\n",
      "    Level 1536: AUC=0.8355, F1=0.0552\n",
      "\n",
      "--- Fold 2/3 ---\n",
      "  Epoch 4/12: Loss = 1.3242\n",
      "  Epoch 8/12: Loss = 1.2016\n",
      "  Epoch 12/12: Loss = 1.1470\n",
      "  Validation Results:\n",
      "    Level  128: AUC=0.7713, F1=0.0319\n",
      "    Level  256: AUC=0.7795, F1=0.0365\n",
      "    Level  512: AUC=0.7785, F1=0.0222\n",
      "    Level 1024: AUC=0.8212, F1=0.0626\n",
      "    Level 1536: AUC=0.8313, F1=0.0736\n",
      "\n",
      "--- Fold 3/3 ---\n",
      "  Epoch 4/12: Loss = 1.3834\n",
      "  Epoch 8/12: Loss = 1.2399\n",
      "  Epoch 12/12: Loss = 1.1816\n",
      "  Validation Results:\n",
      "    Level  128: AUC=0.7945, F1=0.0348\n",
      "    Level  256: AUC=0.7978, F1=0.0313\n",
      "    Level  512: AUC=0.8042, F1=0.0386\n",
      "    Level 1024: AUC=0.8391, F1=0.0605\n",
      "    Level 1536: AUC=0.8443, F1=0.0640\n",
      "\n",
      "========================================\n",
      "FINAL MIMIC MRL RESULTS\n",
      "========================================\n",
      "Level  128: AUC = 0.7824 ± 0.0095\n",
      "Level  256: AUC = 0.7888 ± 0.0075\n",
      "Level  512: AUC = 0.7875 ± 0.0118\n",
      "Level 1024: AUC = 0.8302 ± 0.0073\n",
      "Level 1536: AUC = 0.8370 ± 0.0054\n",
      "\n",
      "============================================================\n",
      "TRAINING MRL ON EMORY DATASET\n",
      "============================================================\n",
      "Dataset: 2000 samples, 1536 dimensions\n",
      "MRL nesting levels: [128, 256, 512, 1024, 1536]\n",
      "Device: cuda\n",
      "Level weights: {128: 2.0, 256: 2.0, 512: 1.5, 1024: 1.5, 1536: 1.0}\n",
      "\n",
      "--- Fold 1/3 ---\n",
      "  Epoch 4/12: Loss = 0.9055\n",
      "  Epoch 8/12: Loss = 0.7612\n",
      "  Epoch 12/12: Loss = 0.7058\n",
      "  Validation Results:\n",
      "    Level  128: AUC=0.7246, F1=0.0053\n",
      "    Level  256: AUC=0.7180, F1=0.0000\n",
      "    Level  512: AUC=0.7350, F1=0.0000\n",
      "    Level 1024: AUC=0.7791, F1=0.0126\n",
      "    Level 1536: AUC=0.7991, F1=0.0632\n",
      "\n",
      "--- Fold 2/3 ---\n",
      "  Epoch 4/12: Loss = 0.8957\n",
      "  Epoch 8/12: Loss = 0.7401\n",
      "  Epoch 12/12: Loss = 0.6886\n",
      "  Validation Results:\n",
      "    Level  128: AUC=0.7815, F1=0.0000\n",
      "    Level  256: AUC=0.7882, F1=0.0197\n",
      "    Level  512: AUC=0.7819, F1=0.0000\n",
      "    Level 1024: AUC=0.8502, F1=0.0233\n",
      "    Level 1536: AUC=0.8355, F1=0.0647\n",
      "\n",
      "--- Fold 3/3 ---\n",
      "  Epoch 4/12: Loss = 0.8901\n",
      "  Epoch 8/12: Loss = 0.7045\n",
      "  Epoch 12/12: Loss = 0.6641\n",
      "  Validation Results:\n",
      "    Level  128: AUC=0.7814, F1=0.0000\n",
      "    Level  256: AUC=0.7877, F1=0.0042\n",
      "    Level  512: AUC=0.7920, F1=0.0000\n",
      "    Level 1024: AUC=0.8334, F1=0.0121\n",
      "    Level 1536: AUC=0.8393, F1=0.0220\n",
      "\n",
      "========================================\n",
      "FINAL EMORY MRL RESULTS\n",
      "========================================\n",
      "Level  128: AUC = 0.7625 ± 0.0268\n",
      "Level  256: AUC = 0.7646 ± 0.0330\n",
      "Level  512: AUC = 0.7696 ± 0.0248\n",
      "Level 1024: AUC = 0.8209 ± 0.0304\n",
      "Level 1536: AUC = 0.8246 ± 0.0182\n",
      "\n",
      "============================================================\n",
      "MRL COMPARISON: MIMIC vs EMORY\n",
      "============================================================\n",
      "Level    MIMIC AUC    Emory AUC    Difference  \n",
      "--------------------------------------------------\n",
      "128      0.7824±0.009  0.7625±0.027  -0.0199\n",
      "256      0.7888±0.007  0.7646±0.033  -0.0242\n",
      "512      0.7875±0.012  0.7696±0.025  -0.0179\n",
      "1024     0.8302±0.007  0.8209±0.030  -0.0093\n",
      "1536     0.8370±0.005  0.8246±0.018  -0.0124\n",
      "\n",
      "🎯 KEY INSIGHTS:\n",
      "✅ Your 4-model fusion approach works across different hospitals\n",
      "✅ MRL provides multiple speed/accuracy tradeoffs\n",
      "✅ Can adapt to different computational budgets\n",
      "\n",
      "📊 PERFORMANCE SUMMARY:\n",
      "MIMIC best: Level 1536 with AUC 0.8370\n",
      "Emory best: Level 1536 with AUC 0.8246\n"
     ]
    }
   ],
   "source": [
    "# Quick fix - let's use a simpler approach and limit to our practical levels only\n",
    "print(\"Training MRL with fixed nesting levels...\")\n",
    "\n",
    "# Limit max dimension to our highest practical level\n",
    "max_practical_dim = 1536\n",
    "\n",
    "# Truncate data to this maximum\n",
    "mimic_truncated = mimic_embeddings[:, :max_practical_dim]\n",
    "emory_truncated = emory_embeddings[:, :max_practical_dim]\n",
    "\n",
    "print(f\"Truncated MIMIC: {mimic_truncated.shape}\")\n",
    "print(f\"Truncated Emory: {emory_truncated.shape}\")\n",
    "\n",
    "# Now train with our practical levels\n",
    "practical_levels = [128, 256, 512, 1024, 1536]\n",
    "\n",
    "# Train MRL on MIMIC\n",
    "mimic_results = train_mrl_on_dataset(\n",
    "    mimic_truncated, mimic_labels, \"MIMIC\", \n",
    "    nesting_levels=practical_levels\n",
    ")\n",
    "\n",
    "# Train MRL on Emory  \n",
    "emory_results = train_mrl_on_dataset(\n",
    "    emory_truncated, emory_labels, \"EMORY\",\n",
    "    nesting_levels=practical_levels\n",
    ")\n",
    "\n",
    "# Compare results\n",
    "compare_datasets_mrl(mimic_results, emory_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4237f0-6fbc-475c-b07d-6081a5641da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
